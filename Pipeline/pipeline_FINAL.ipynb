{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":["hiTPgJ8U-p6Y"],"machine_shape":"hm","gpuType":"L4","authorship_tag":"ABX9TyM4OJdod6giY0IRqwIikVfH"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"b4c774008fd843bcb3a616dd05b060f4":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_6a0e8f03675c477696301d59a02cce1f","IPY_MODEL_3aae6d344fe0407c8ce8b3191ea18f27","IPY_MODEL_30df408a2187415fbd09acfb1554f93e"],"layout":"IPY_MODEL_906040d61942440b8e432c1f4bb261a4"}},"6a0e8f03675c477696301d59a02cce1f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_958e4fed9bc64c7ba79f892307eacf0f","placeholder":"​","style":"IPY_MODEL_3c88eac49d08405e9f82216a8fafd437","value":"config.json: 100%"}},"3aae6d344fe0407c8ce8b3191ea18f27":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_d7d9bfd8d0694148b973eb375b8a7daa","max":1392,"min":0,"orientation":"horizontal","style":"IPY_MODEL_f690674d9f2143d1a5cb51964d8f6e46","value":1392}},"30df408a2187415fbd09acfb1554f93e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2dbf466d34224373a02e7159104d13a0","placeholder":"​","style":"IPY_MODEL_692fb6ca31084fabb4db1d341dca7fee","value":" 1.39k/1.39k [00:00&lt;00:00, 152kB/s]"}},"906040d61942440b8e432c1f4bb261a4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"958e4fed9bc64c7ba79f892307eacf0f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3c88eac49d08405e9f82216a8fafd437":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d7d9bfd8d0694148b973eb375b8a7daa":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f690674d9f2143d1a5cb51964d8f6e46":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"2dbf466d34224373a02e7159104d13a0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"692fb6ca31084fabb4db1d341dca7fee":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f3902c8ad8924c2a8ba2cbb3796e1eca":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_842d0e370aaf4968b772b3f1450134b0","IPY_MODEL_69527697655e4e8282c3fd63b969f015","IPY_MODEL_71711004ab924792b27302288e17ffa7"],"layout":"IPY_MODEL_8cb4fd1dff294354ad65f0cde033caf2"}},"842d0e370aaf4968b772b3f1450134b0":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_bfeb7abfba5f4a498c53d79be933fb18","placeholder":"​","style":"IPY_MODEL_56c7a200208341c296a21970acbe2b31","value":"pytorch_model.bin: 100%"}},"69527697655e4e8282c3fd63b969f015":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_37efdbf1bacc45d18dbec2cccd0234c0","max":2275329241,"min":0,"orientation":"horizontal","style":"IPY_MODEL_101cea7215c84166992693340ffde0a2","value":2275329241}},"71711004ab924792b27302288e17ffa7":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c26d7db227744bd881278f521231c48a","placeholder":"​","style":"IPY_MODEL_9e80948db36b4b05ac9aa3ebd12c0956","value":" 2.28G/2.28G [00:04&lt;00:00, 424MB/s]"}},"8cb4fd1dff294354ad65f0cde033caf2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bfeb7abfba5f4a498c53d79be933fb18":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"56c7a200208341c296a21970acbe2b31":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"37efdbf1bacc45d18dbec2cccd0234c0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"101cea7215c84166992693340ffde0a2":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"c26d7db227744bd881278f521231c48a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9e80948db36b4b05ac9aa3ebd12c0956":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7b0d4bc659ff402494b9b44c185200f2":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_be63090da6cb4e7cbdfdc61dd6a194fa","IPY_MODEL_7583872aaef94da28e24047d32d64cda","IPY_MODEL_2d30991682564dd899f2b9dc015170bd"],"layout":"IPY_MODEL_3d0010c5bec34b7cb2e8996b05674db3"}},"be63090da6cb4e7cbdfdc61dd6a194fa":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2868fbda9a704a3e969d20929974d8c0","placeholder":"​","style":"IPY_MODEL_37bbb6ff60b5412aae78a0a0ac592eab","value":"model.safetensors: 100%"}},"7583872aaef94da28e24047d32d64cda":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_df65aaca42d848d1a8b7b573ada2a301","max":2275264548,"min":0,"orientation":"horizontal","style":"IPY_MODEL_94ad5def517648fcb2e1b73b8b17999d","value":2275264548}},"2d30991682564dd899f2b9dc015170bd":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9ff3922945144a16b6764aa2c4b65987","placeholder":"​","style":"IPY_MODEL_30cc89e84af048a885fa08972624e67e","value":" 2.28G/2.28G [00:09&lt;00:00, 403MB/s]"}},"3d0010c5bec34b7cb2e8996b05674db3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2868fbda9a704a3e969d20929974d8c0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"37bbb6ff60b5412aae78a0a0ac592eab":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"df65aaca42d848d1a8b7b573ada2a301":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"94ad5def517648fcb2e1b73b8b17999d":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"9ff3922945144a16b6764aa2c4b65987":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"30cc89e84af048a885fa08972624e67e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1ad6bb8438ad4c18a09d97fa35aa15fd":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_3e6b7f62152c472e8290111f3a0be0cf","IPY_MODEL_37cf33b5bacb44d6b03147b179679ba8","IPY_MODEL_738197a427d64362b50d4a9634cf1719"],"layout":"IPY_MODEL_4db7188de0924ecbaee66a9f5e15a96f"}},"3e6b7f62152c472e8290111f3a0be0cf":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_bb7504243f6a438d9120fae94021b486","placeholder":"​","style":"IPY_MODEL_3639fd57424a4b02822812c48ae44bd7","value":"generation_config.json: 100%"}},"37cf33b5bacb44d6b03147b179679ba8":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_4f07eb0502b347489a5cc0e7e41194b8","max":259,"min":0,"orientation":"horizontal","style":"IPY_MODEL_3f8d4572768f4bbba012f50aeda80ab3","value":259}},"738197a427d64362b50d4a9634cf1719":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0eaafd390a8b47e2bde9455c385aaeaa","placeholder":"​","style":"IPY_MODEL_490db3eb4c074eb4973e8a533eb0a281","value":" 259/259 [00:00&lt;00:00, 27.8kB/s]"}},"4db7188de0924ecbaee66a9f5e15a96f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bb7504243f6a438d9120fae94021b486":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3639fd57424a4b02822812c48ae44bd7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4f07eb0502b347489a5cc0e7e41194b8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3f8d4572768f4bbba012f50aeda80ab3":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"0eaafd390a8b47e2bde9455c385aaeaa":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"490db3eb4c074eb4973e8a533eb0a281":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FLuvJVryEadR","executionInfo":{"status":"ok","timestamp":1750750823113,"user_tz":-420,"elapsed":1388,"user":{"displayName":"Unforgiven The","userId":"10817091228202119239"}},"outputId":"ae92ad3e-eb37-4069-9394-87e9dd7916db"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["import torch\n","\n","device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n","print(device)\n","torch_device = torch.device(device)\n","print(torch_device)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bPALG-6zIAsz","executionInfo":{"status":"ok","timestamp":1750750825466,"user_tz":-420,"elapsed":1663,"user":{"displayName":"Unforgiven The","userId":"10817091228202119239"}},"outputId":"6a8d7f2e-26c9-4a95-a1fd-04f1454b60b1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["cuda:0\n","cuda:0\n"]}]},{"cell_type":"markdown","source":["# Install"],"metadata":{"id":"EyicOXACFWqS"}},{"cell_type":"markdown","source":["- Database"],"metadata":{"id":"Jj7O3yZI0ajh"}},{"cell_type":"code","source":["!pip install -q pymongo"],"metadata":{"id":"ZFRTHMRV0cdQ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["- Speech2Text"],"metadata":{"id":"HzBW9HadFYwx"}},{"cell_type":"code","source":["!pip install -q --upgrade pip\n","!pip install -q --upgrade transformers datasets[audio] accelerate\n","# !pip install -q --upgrade transformers accelerate\n","!pip install -q torch torchvision torchaudio\n","!pip install -q pyannote.audio\n","!pip install -q -U openai-whisper"],"metadata":{"collapsed":true,"id":"GpFMM2JnFX2h"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Import"],"metadata":{"id":"2fau6PFREv9B"}},{"cell_type":"markdown","source":["### Framework"],"metadata":{"id":"Oe-ctZbhGGXj"}},{"cell_type":"code","source":["import os\n","from pathlib import Path\n","from io import BytesIO\n","import librosa\n","\n","import re\n","import string\n","import json\n","from google.colab import output\n","import time\n","import pandas as pd\n","import numpy as np\n","import unicodedata\n","import collections\n","from copy import deepcopy"],"metadata":{"id":"Oo4faKI2FPLx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Database\n","from pymongo.mongo_client import MongoClient\n","from pymongo.server_api import ServerApi\n","import gridfs\n","from bson import ObjectId"],"metadata":{"id":"dlpKC6CdsKtE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from IPython.display import Javascript\n","from IPython.display import Audio"],"metadata":{"id":"39DCmDlG05Hu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Speech2Text\n","import shutil\n","import subprocess\n","from IPython.display import Javascript\n","from IPython.display import Audio\n","from base64 import b64decode\n","\n","from transformers import AutoModelForSpeechSeq2Seq, AutoProcessor, pipeline\n","import whisper\n","from whisper import load_model\n","\n","# Diarization\n","from pyannote.audio import Pipeline"],"metadata":{"id":"ScdqXXlgE-Vf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# SOAP Gen\n","from transformers import (\n","    AutoModelForSeq2SeqLM,\n","    AutoTokenizer,\n","    GenerationConfig,\n","    TrainingArguments,\n","    Trainer,\n","    PegasusForConditionalGeneration,\n","    PegasusTokenizer,\n","    PegasusTokenizerFast,\n",")\n","\n","from peft import PeftModel, PeftConfig, get_peft_model_state_dict"],"metadata":{"id":"U0gQQCdTFCxv"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Implement"],"metadata":{"id":"G29RQkODE3hQ"}},{"cell_type":"markdown","source":["### Utils"],"metadata":{"id":"V9Hx0qy9Fs8h"}},{"cell_type":"code","source":["def save_to_json(data, filename):\n","    with open(filename, 'w') as f:\n","        json.dump(data, f, indent=4)\n","    print(f\"Saved to: {filename}\")\n","\n","def load_from_json(filename):\n","    \"\"\"\n","    Load the conversation from a JSON file.\n","    \"\"\"\n","    with open(filename, 'r') as f:\n","        return json.load(f)\n","\n","def convert_to_wav(input_path: str, output_path: str) -> str:\n","    # Ensure the output path has .wav extension\n","    output_wav_path = str(Path(output_path).with_suffix(\".wav\"))\n","\n","    subprocess.run([\n","        \"ffmpeg\", \"-y\", \"-i\", input_path,\n","        \"-ac\", \"1\", \"-ar\", \"16000\", output_wav_path\n","    ], check=True)\n","\n","    return output_wav_path"],"metadata":{"id":"6XgK3YKgFskg"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Database"],"metadata":{"id":"JXPI_RMPsXF2"}},{"cell_type":"code","source":["# === Connect to DB ===\n","def connect_to_db(uri: str, db_name: str):\n","    client = MongoClient(uri)\n","    db = client[db_name]\n","    try:\n","        client.admin.command('ping')\n","        print(\"Pinged your deployment. You successfully connected to MongoDB!\")\n","    except Exception as e:\n","        print(e)\n","    return db, gridfs.GridFS(db)\n","\n","# === Insert Audio File ===\n","def upload_audio(fs, file_path: str):\n","    with open(file_path, \"rb\") as f:\n","        audio_id = fs.put(f, filename=os.path.basename(file_path))\n","    return audio_id\n","\n","# === Insert Full Conversation Record ===\n","def insert_conversation(db, name, audio_id: ObjectId, transcript: list, word_transcript: list, summary: dict):\n","    conversation = {\n","        \"name\": name,\n","        \"audio_id\": audio_id,\n","        \"transcript\": transcript,\n","        \"word_transcript\": word_transcript,\n","        \"summary\": summary\n","    }\n","    result = db[\"conversation\"].insert_one(conversation)\n","    return result.inserted_id\n","\n","# === Retrieve a Record ===\n","def get_conversation(db, conversation_id: str):\n","    return db[\"conversation\"].find_one({\"_id\": ObjectId(conversation_id)})\n","\n","# === Get Audio by ID ===\n","def get_audio(fs, audio_id: str):\n","    return fs.get(ObjectId(audio_id)).read()\n","\n","# === Download Audio by ID ===\n","def download_audio(fs, audio_id: str, save_path: str):\n","    data = fs.get(ObjectId(audio_id)).read()\n","    with open(save_path, \"wb\") as f:\n","        f.write(data)"],"metadata":{"id":"DR0hQkf8sZij"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Dialogue2Text"],"metadata":{"id":"FYfZSRd0E6zB"}},{"cell_type":"code","source":["def transcribe_with_whisper(audio_path, model, language=\"en\"):\n","    \"\"\"Run Whisper to get a list of tokens with timestamps.\"\"\"\n","    # word_timestamps=True for word-level timing\n","    result = model.transcribe(\n","        audio_path,\n","        word_timestamps=True,\n","        language=language  # \"en\", \"vi\", \"ja\"\n","    )\n","    # result[\"segments\"] is a list of dicts with words inside\n","    tokens = []\n","    for seg in result[\"segments\"]:\n","        for word_info in seg[\"words\"]:\n","            tokens.append({\n","                \"word\": word_info[\"word\"].strip(),\n","                \"start\": round(word_info[\"start\"], 2),\n","                \"end\":   round(word_info[\"end\"], 2)\n","            })\n","    return tokens\n","\n","def diarize_with_pyannote(audio_path, pipeline, device=\"cuda\"):\n","    \"\"\"Run pyannote speaker diarization pipeline.\"\"\"\n","    pipeline.to(torch.device(device))\n","    diarization = pipeline({\"audio\": audio_path})\n","\n","    segments = [\n","        {\n","            \"start\": round(turn.start, 2),\n","            \"end\": round(turn.end, 2),\n","            \"speaker\": speaker\n","        }\n","        for turn, _, speaker in diarization.itertracks(yield_label=True)\n","    ]\n","\n","    return segments\n","\n","def assign_speakers(tokens, segments):\n","    \"\"\"\n","    For each token, find the diarization segment it falls into.\n","    If no segment covers its start time, assign 'UNK'.\n","    \"\"\"\n","    diarized_tokens = []\n","    idx = 0\n","    # sort segments by start time\n","    segments = sorted(segments, key=lambda x: x[\"start\"])\n","    for token in tokens:\n","        # advance idx until segment might cover token\n","        while idx + 1 < len(segments) and segments[idx][\"end\"] < token[\"start\"]:\n","            idx += 1\n","        seg = segments[idx]\n","        speaker = seg[\"speaker\"] if seg[\"start\"] <= token[\"start\"] <= seg[\"end\"] else \"UNK\"\n","        diarized_tokens.append({**token, \"speaker\": speaker})\n","    return diarized_tokens\n","\n","def build_diarized_transcript(diarized_tokens):\n","    \"\"\"\n","    Group contiguous tokens with same speaker into utterances.\n","    Returns list of {speaker, start, end, text}.\n","    \"\"\"\n","    if not diarized_tokens:\n","        return []\n","    utterances = []\n","    cur = {\n","        \"speaker\": diarized_tokens[0][\"speaker\"],\n","        \"start\":   diarized_tokens[0][\"start\"],\n","        \"end\":     diarized_tokens[0][\"end\"],\n","        \"text\":    diarized_tokens[0][\"word\"]\n","    }\n","    for tok in diarized_tokens[1:]:\n","        if tok[\"speaker\"] == cur[\"speaker\"]:\n","            cur[\"end\"] = tok[\"end\"]\n","            cur[\"text\"] += \" \" + tok[\"word\"]\n","        else:\n","            utterances.append(cur)\n","            cur = {\n","                \"speaker\": tok[\"speaker\"],\n","                \"start\":   tok[\"start\"],\n","                \"end\":     tok[\"end\"],\n","                \"text\":    tok[\"word\"]\n","            }\n","    utterances.append(cur)\n","    return utterances\n","\n","def merge_unk_into_next(utterances):\n","    \"\"\"\n","    Given a list of {'speaker','start','end','text'} utterances,\n","    merge any UNK utterance into the next real speaker.\n","    \"\"\"\n","    merged = []\n","    i = 0\n","    while i < len(utterances):\n","        utt = utterances[i]\n","        # If this is an UNK and there *is* a following utterance, merge it there\n","        if utt[\"speaker\"] == \"UNK\" and i + 1 < len(utterances):\n","            next_utt = utterances[i + 1]\n","            # prepend the UNK text and adjust the start time\n","            next_utt[\"text\"]  = utt[\"text\"] + \" \" + next_utt[\"text\"]\n","            next_utt[\"start\"] = utt[\"start\"]\n","            # we skip appending utt itself\n","        else:\n","            # regular speaker, just keep it\n","            merged.append(utt)\n","        i += 1\n","    return merged\n","\n","def add_utterance_ids(utterances, prefix=\"U\"):\n","    \"\"\"\n","    Parameters:\n","        utterances (list of dict): List of utterance dictionaries.\n","        prefix (str): Prefix for utterance IDs, default is 'U'.\n","\n","    Returns:\n","        list of dict: Modified list with 'utterance_id' added to each item.\n","    \"\"\"\n","    for i, utt in enumerate(utterances, start=1):\n","        utt[\"utterance_id\"] = f\"{prefix}{i}\"\n","    return utterances\n","\n","def process_audio(audio_path, model_whisper, pipeline_diarization):\n","    # Whisper\n","    tokens = transcribe_with_whisper(audio_path, model_whisper, \"en\")\n","\n","    # Pyannote\n","    segments = diarize_with_pyannote(audio_path, pipeline_diarization, device=\"cuda\")\n","\n","    # Process\n","    diarized_tokens = assign_speakers(tokens, segments)\n","    raw_utterances = build_diarized_transcript(diarized_tokens)\n","    clean_utterances = merge_unk_into_next(raw_utterances)\n","    clean_utterances = add_utterance_ids(clean_utterances, \"U\")\n","\n","    return tokens, clean_utterances"],"metadata":{"id":"gJwFxcV4FqGB"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Role Classifier"],"metadata":{"id":"C0kuncOCFGih"}},{"cell_type":"code","source":["# Doctor indicators\n","doctor_keywords = [\n","    # Questions and inquiries\n","    \"what brings you\", \"how are you feeling\", \"how long have you\", \"when did this start\",\n","    \"can you describe\", \"tell me about\", \"any other symptoms\", \"have you experienced\",\n","    \"do you have any\", \"are you taking\", \"have you tried\", \"how would you rate\",\n","    \"on a scale of\", \"does it hurt when\", \"can you point to\", \"how often do you\",\n","\n","    # Medical examination language\n","    \"let me examine\", \"i'm going to\", \"let me check\", \"i need to\", \"let me listen\",\n","    \"take a deep breath\", \"say ah\", \"follow my finger\", \"look up\", \"look down\",\n","    \"turn your head\", \"can you lift\", \"does this hurt\", \"feel any pressure\",\n","\n","    # Medical recommendations and instructions\n","    \"i recommend\", \"you should\", \"i suggest\", \"my advice\", \"you need to\",\n","    \"take this\", \"apply this\", \"rest for\", \"avoid\", \"come back in\",\n","    \"follow up\", \"schedule\", \"return if\", \"call if\", \"monitor\",\n","\n","    # Medical terminology and diagnosis\n","    \"diagnosis\", \"condition\", \"infection\", \"inflammation\", \"prescription\",\n","    \"medication\", \"treatment\", \"therapy\", \"procedure\", \"test results\",\n","    \"blood work\", \"x-ray\", \"scan\", \"allergy\", \"dosage\", \"side effects\",\n","    \"medical history\", \"family history\", \"chronic\", \"acute\", \"symptoms indicate\",\n","\n","    # Professional phrases\n","    \"in my opinion\", \"based on\", \"it appears\", \"it looks like\", \"i believe\",\n","    \"we need to rule out\", \"differential diagnosis\", \"likely cause\", \"i suspect\"\n","]\n","\n","# Comprehensive patient indicators\n","patient_keywords = [\n","    # Personal symptoms and feelings\n","    \"i have\", \"i feel\", \"i'm experiencing\", \"i've been having\", \"i get\",\n","    \"i notice\", \"i can't\", \"i'm unable to\", \"it hurts\", \"it's painful\",\n","    \"i'm worried\", \"i'm concerned\", \"i think\", \"i believe\", \"i'm afraid\",\n","\n","    # Pain and discomfort descriptions\n","    \"hurts\", \"pain\", \"painful\", \"ache\", \"aching\", \"sore\", \"tender\",\n","    \"burning\", \"stinging\", \"throbbing\", \"sharp\", \"dull\", \"cramping\",\n","    \"tight\", \"pressure\", \"uncomfortable\", \"bothering me\", \"killing me\",\n","\n","    # Symptom descriptions\n","    \"sick\", \"nauseous\", \"dizzy\", \"tired\", \"weak\", \"fever\", \"chills\",\n","    \"headache\", \"stomach ache\", \"runny nose\", \"cough\", \"congested\",\n","    \"swollen\", \"rash\", \"itchy\", \"blurry\", \"ringing\", \"numbness\",\n","\n","    # Personal references and possessives\n","    \"my head\", \"my back\", \"my stomach\", \"my chest\", \"my throat\", \"my arm\",\n","    \"my leg\", \"my eye\", \"my ear\", \"my skin\", \"my heart\", \"my breathing\",\n","\n","    # Timeline and frequency from patient perspective\n","    \"started yesterday\", \"been going on\", \"happens when\", \"gets worse\",\n","    \"feels better\", \"comes and goes\", \"all the time\", \"at night\", \"in the morning\",\n","    \"after eating\", \"before bed\", \"during\", \"since\", \"for days\", \"for weeks\",\n","\n","    # Lifestyle and personal context\n","    \"i work\", \"i sleep\", \"i eat\", \"i drink\", \"i smoke\", \"i exercise\",\n","    \"i live\", \"i usually\", \"normally i\", \"my job\", \"my family\", \"my wife\",\n","    \"my husband\", \"my kids\", \"at home\", \"at work\"\n","]\n","\n","def role_classification(dialogue, doctor_keywords, patient_keywords):\n","    \"\"\"\n","    Fallback classification using rule-based approach if API fails.\n","    \"\"\"\n","    speakers = list(set(segment[\"speaker\"] for segment in dialogue))\n","\n","    if len(speakers) != 2:\n","        # If not exactly 2 speakers, return default mapping\n","        return {speaker: \"Unknown\" for speaker in speakers}\n","\n","    speaker_analysis = {}\n","\n","    for speaker in speakers:\n","        speaker_texts = [seg[\"text\"] for seg in dialogue if seg[\"speaker\"] == speaker]\n","        combined_text = \" \".join(speaker_texts).lower()\n","\n","        # Rule-based scoring\n","        doctor_score = 0\n","        patient_score = 0\n","\n","        for keyword in doctor_keywords:\n","            if keyword in combined_text:\n","                doctor_score += 1\n","\n","        for keyword in patient_keywords:\n","            if keyword in combined_text:\n","                patient_score += 1\n","\n","        # # First speaker is often doctor (greeting pattern)\n","        # if dialogue[0][\"speaker\"] == speaker and any(word in dialogue[0][\"text\"].lower()\n","        #                                            for word in [\"hello\", \"hi\", \"good\"]):\n","        #     doctor_score += 2\n","\n","        speaker_analysis[speaker] = {\"doctor_score\": doctor_score, \"patient_score\": patient_score}\n","\n","    # Assign roles based on scores\n","    result = {}\n","    speakers_by_doctor_score = sorted(speakers,\n","                                    key=lambda x: speaker_analysis[x][\"doctor_score\"],\n","                                    reverse=True)\n","\n","    result[speakers_by_doctor_score[0]] = \"Doctor\"\n","    result[speakers_by_doctor_score[1]] = \"Patient\"\n","\n","    return result\n","\n","def replace_speaker_labels(transcript, speaker_labels):\n","    \"\"\"\n","    Replace speaker labels in transcript with classified roles.\n","\n","    Args:\n","        transcript List[Dict[str, Any]]: List of dialogue segments with speaker, start, end, and text\n","        speaker_labels : Dict[str, str]: Dictionary mapping original speaker IDs to roles (e.g., {\"SPEAKER_00\": \"Doctor\", \"SPEAKER_01\": \"Patient\"})\n","\n","    Returns:\n","        -> List[Dict[str, Any]]: List of dialogue segments with updated speaker labels\n","    \"\"\"\n","    updated_transcript = []\n","\n","    for segment in transcript:\n","        # Create a copy of the segment to avoid modifying the original\n","        updated_segment = segment.copy()\n","\n","        # Replace the speaker label with the classified role\n","        original_speaker = segment[\"speaker\"]\n","        if original_speaker in speaker_labels:\n","            updated_segment[\"speaker\"] = speaker_labels[original_speaker]\n","        else:\n","            # Keep original label if not found in speaker_labels\n","            print(f\"Warning: Speaker '{original_speaker}' not found in speaker_labels. Keeping original label.\")\n","\n","        updated_transcript.append(updated_segment)\n","\n","    return updated_transcript\n","\n","def classify_speakers(transcript, doctor_keywords, patient_keywords):\n","    transcript_speakers = role_classification(transcript, doctor_keywords, patient_keywords)\n","    transcript_labelled = replace_speaker_labels(transcript, transcript_speakers)\n","    return transcript_labelled"],"metadata":{"id":"6LOmfLN9HZhj"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### SOAP Gen"],"metadata":{"id":"Qi5bxIqnFH0R"}},{"cell_type":"code","source":["def transcript2string(utterances: list[dict]) -> str:\n","    dialogue_lines = [\n","        f\"{entry['speaker']}: {entry['text'].strip()}\"\n","        for entry in utterances\n","        if 'speaker' in entry and 'text' in entry\n","    ]\n","    return \"\\n\".join(dialogue_lines)"],"metadata":{"id":"kd0wAUMyHnNz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def process_soap_traceability(dialogue, tok, tok_fast, ft_model):\n","    # split into utterances + IDs --------------------------------------\n","    parts = re.split(r'(Doctor:|Patient:)', dialogue)[1:]\n","    utterances = [parts[i] + parts[i + 1] for i in range(0, len(parts), 2)]\n","    utterance_ids = [f\"U{i+1}\" for i in range(len(utterances))]\n","    # dict: utt - utt_id\n","    utt_dict = {uid: utt.strip() for uid, utt in zip(utterance_ids, utterances)}\n","\n","    # --- map *encoder* tokens → utterance -----------------------------\n","    enc_inputs   = tok(dialogue, return_tensors=\"pt\", max_length=512, truncation=True).to(device)\n","    enc_tokens   = tok.convert_ids_to_tokens(enc_inputs[\"input_ids\"][0])\n","\n","    token_to_utt = []\n","    cur_utt_idx  = 0\n","    utt_starts   = []\n","    for i, utt in enumerate(utterances):\n","        first_piece = tok.tokenize(utt.strip())[0]\n","        try:\n","            pos = enc_tokens.index(first_piece,\n","                                  utt_starts[-1] + 1 if i else 0)\n","        except ValueError:\n","            pos = utt_starts[-1] if utt_starts else 0\n","        utt_starts.append(pos)\n","\n","    for i in range(len(enc_tokens)):\n","        j = max(j for j, start in enumerate(utt_starts) if i >= start)\n","        token_to_utt.append(utterance_ids[j])\n","\n","    # ------------------------------------------------------------------\n","    # 3) GENERATE SOAP summary -----------------------------------------\n","    gen_ids = ft_model.generate(**enc_inputs, generation_config=gen_cfg)\n","    summary_text   = tok_fast.decode(gen_ids[0],\n","                                    skip_special_tokens=True,\n","                                    clean_up_tokenization_spaces=True)\n","\n","    print(f\"[INFO] Generated summary length: {len(summary_text)} characters, {len(gen_ids[0])} tokens\")\n","\n","    # Forced decoding to get attentions\n","    with torch.no_grad():\n","        outs = ft_model(**enc_inputs, labels=gen_ids, output_attentions=True)\n","\n","    # (layers, b, h, dec_len, enc_len)\n","    all_xattn = torch.stack(outs.cross_attentions, dim=0)\n","    avg_xattn = all_xattn.mean(dim=(0, 2))[0]                    # (dec_len, enc_len)\n","\n","    # ---------------------------------------------------------------\n","    # Decoder tokens without specials\n","    enc_summary = tok_fast(summary_text,\n","                          add_special_tokens=False,\n","                          return_offsets_mapping=True)\n","\n","    dec_tokens  = tok_fast.convert_ids_to_tokens(enc_summary[\"input_ids\"])\n","    offsets     = enc_summary[\"offset_mapping\"]           # (dec_len, 2)\n","\n","    # ---------------------------------------------------------------\n","    # Align rows ↔ dec_tokens 1-to-1\n","    bos_id, eos_id = tok_fast.bos_token_id, tok_fast.eos_token_id\n","    keep_mask_full = (gen_ids[0] != bos_id) & (gen_ids[0] != eos_id)\n","    keep_mask = keep_mask_full[:-1]  # Trim 1 element: drop the final position because EOS has **no** cross-attn row\n","\n","    # avg_xattn = avg_xattn[keep_mask]\n","    # avg_xattn = avg_xattn[:len(dec_tokens)]\n","    avg_xattn = avg_xattn[:len(dec_tokens), :]\n","    # avg_xattn = avg_xattn[1:]\n","\n","    if avg_xattn.shape[0] != len(dec_tokens):\n","        print(\"Warning: shape mismatch after filtering special tokens:\",\n","              avg_xattn.shape[0], \"rows vs\", len(dec_tokens), \"decoder tokens\")\n","\n","    tok_char_starts = [off[0] for off in offsets]\n","\n","\n","    # ------------------------------------------------------------------\n","    # 4) PARSE SOAP into sections + sentences --------------------------\n","    soap_sec_pat = re.compile(r'\\b([SOAP]):')\n","    matches      = list(soap_sec_pat.finditer(summary_text))\n","    sent_entries = []                       # [{section,S/O/A/P; idx; start; end; text}]\n","\n","    for idx, m in enumerate(matches):\n","        sec = m.group(1)\n","        start_txt = m.end()\n","        end_txt   = matches[idx+1].start() if idx+1 < len(matches) else len(summary_text)\n","        section_text = summary_text[start_txt:end_txt].strip()\n","\n","        # split into sentences\n","        sent_pats = re.split(r'(?<=[.!?])\\s+', section_text)\n","        cursor = start_txt\n","        local_idx = 0\n","        for s in sent_pats:\n","            s_clean = s.strip()\n","            if not s_clean:\n","                continue\n","            s_start = summary_text.find(s_clean, cursor, end_txt)\n","            s_end   = s_start + len(s_clean)\n","            sent_entries.append({\n","                \"section\":   sec,\n","                \"sent_idx\":  local_idx,\n","                \"start\":     s_start,\n","                \"end\":       s_end,\n","                \"text\":      s_clean,\n","            })\n","            cursor     = s_end + 1\n","            local_idx += 1\n","\n","    # map decoder-token pos → sentence index ---------------------------\n","    tok2sent = []\n","    cur_sent = 0\n","    for pos in tok_char_starts:\n","        while (cur_sent + 1 < len(sent_entries) and\n","              pos >= sent_entries[cur_sent + 1][\"start\"]):\n","            cur_sent += 1\n","        tok2sent.append(cur_sent)\n","\n","    # ------------------------------------------------------------------\n","    # 5) CROSS-ATTENTION -----------------------------------------------\n","\n","    SPECIALS = set(tok_fast.all_special_tokens)\n","    SECTION_TOKENS = {\"▁S\", \"▁O\", \"▁A\", \"▁P\", \"S\", \"O\", \"A\", \"P\"}\n","    STOP_WORDS = {\n","        \"the\", \"a\", \"an\", \"and\", \"or\", \"but\", \"if\", \"with\", \"of\", \"for\", \"to\",\n","        \"in\", \"on\", \"at\", \"by\", \"is\", \"are\", \"was\", \"were\", \"be\", \"been\", \"am\",\n","        \"it\", \"this\", \"that\", \"these\", \"those\", \"as\", \"has\", \"have\", \"had\",\n","    }\n","\n","    def all_punct(text: str) -> bool:\n","        \"\"\"True if every character in text is Unicode punctuation.\"\"\"\n","        return all(unicodedata.category(ch).startswith(\"P\") for ch in text)\n","\n","    def is_skip(tok):\n","        t = tok.replace('▁', '').lower()\n","\n","        return (\n","            t in string.punctuation        # ← punctuation\n","            or t in STOP_WORDS             # ← stop-word list you defined\n","            or tok in SPECIALS             # ← <pad>, </s>, <s> …\n","            or tok in SECTION_TOKENS\n","            or t == \"\"                     # ← empty after stripping ▁\n","            or t in {\"\", \"<pad>\", \"</s>\"}\n","            or all_punct(t)\n","        )\n","\n","    top_k_token_att = 5 # keep k strongest attentions\n","    # ------------------------------------------------------------------\n","    # 6) TOKEN-LEVEL vote (top-k enc tokens) ---------------------------\n","    token_vote_utt_dict = {}      # dec_pos -> winner utterance (e.g. 3: \"U1\")\n","    token_top_utts      = {}      # dec_pos -> [k] utterances  (e.g. 3: ['U1', 'U1', 'U1']) # debug only\n","\n","    for dpos, scores in enumerate(avg_xattn):            # dpos indexes dec_tokens\n","        if is_skip(dec_tokens[dpos]):                    # skip punc / stop-words / specials\n","            continue                                     #  ↳ not stored anywhere\n","\n","\n","        # Sort encoder tokens by attention scores, take top-k non-skipped ones.\n","        keep = []\n","        for idx in torch.argsort(scores, descending=True):\n","            if not is_skip(enc_tokens[idx]):\n","                keep.append(int(idx))\n","                if len(keep) == top_k_token_att:         # got k, stop\n","                    break\n","        if not keep:                                     # Rare case: all top-k are skipped\n","            continue\n","\n","        # Map encoder token indices to utterance IDs using token_to_utt.\n","        utts   = [token_to_utt[i] for i in keep]\n","        win    = collections.Counter(utts).most_common(1)[0][0]\n","\n","        token_vote_utt_dict[dpos] = win\n","        token_top_utts[dpos]      = utts                # debug only\n","\n","    # ------------------------------------------------------------------\n","    # 7) SENTENCE-LEVEL vote -------------------------------------------\n","    # Map decoder token → sentence index\n","    tok2sent = []\n","    cur_sent = 0\n","    for start_char, _ in offsets:                        # offsets length == dec_tokens\n","        while cur_sent + 1 < len(sent_entries) and start_char >= sent_entries[cur_sent + 1][\"start\"]:\n","            cur_sent += 1\n","        tok2sent.append(cur_sent)\n","\n","    # Majority vote for each sentence\n","    for global_idx, s in enumerate(sent_entries):\n","        winners = [token_vote_utt_dict[d]\n","            for d, sid in enumerate(tok2sent)\n","                if sid == global_idx and d in token_vote_utt_dict]\n","        s[\"utterance_id\"] = (\n","            collections.Counter(winners).most_common(1)[0][0] if winners else \"Unknown\"\n","        )\n","\n","    # ------------------------------------------------------------------\n","    # 8) BUILD FINAL JSON ----------------------------------------------\n","    final = {\"utterances\": utt_dict,        # 🔹NEW section\n","            \"S\": [], \"O\": [], \"A\": [], \"P\": []}\n","\n","    for sent in sent_entries:\n","        final[sent[\"section\"]].append({\n","            \"sentence_idx\":  str(sent[\"sent_idx\"]),\n","            \"sentence_text\": sent[\"text\"],\n","            \"utterance_id\":  sent[\"utterance_id\"],\n","        })\n","\n","    return final"],"metadata":{"id":"AZD_pQ6FInvy"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Initialize"],"metadata":{"id":"QknpQFIXtAM2"}},{"cell_type":"code","source":["from google.colab import userdata"],"metadata":{"id":"Kr1SpgN2sHDn"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Database"],"metadata":{"id":"1RjS8u4ktZfn"}},{"cell_type":"code","source":["uri = userdata.get('URI_MONGODB')\n","db, fs = connect_to_db(uri, \"thesis\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JQ99g06ttawU","executionInfo":{"status":"ok","timestamp":1750750892017,"user_tz":-420,"elapsed":53,"user":{"displayName":"Unforgiven The","userId":"10817091228202119239"}},"outputId":"67724814-ad7f-46e0-8230-96b7466c4099"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Pinged your deployment. You successfully connected to MongoDB!\n"]}]},{"cell_type":"markdown","source":["### Dialogue2Text"],"metadata":{"id":"U_HY8Pu4tCwl"}},{"cell_type":"code","source":["# Whisper\n","model_whisper=\"large-v3\"\n","model_whisper = load_model(model_whisper, device=device)"],"metadata":{"id":"54FwkKVJ4VpI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Pyannote\n","HF_TOKEN = userdata.get('HF_TOKEN_2')\n","pipeline_name = \"pyannote/speaker-diarization\"\n","pipeline_diarization = Pipeline.from_pretrained(pipeline_name, use_auth_token=HF_TOKEN).to(torch_device)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"F-GYx-rVtG6F","executionInfo":{"status":"ok","timestamp":1750750930864,"user_tz":-420,"elapsed":2536,"user":{"displayName":"Unforgiven The","userId":"10817091228202119239"}},"outputId":"84f31223-db29-473f-d14e-4d9f6a7c6c0f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["DEBUG:speechbrain.utils.checkpoints:Registered checkpoint save hook for _speechbrain_save\n","DEBUG:speechbrain.utils.checkpoints:Registered checkpoint load hook for _speechbrain_load\n","DEBUG:speechbrain.utils.checkpoints:Registered checkpoint save hook for save\n","DEBUG:speechbrain.utils.checkpoints:Registered checkpoint load hook for load\n","DEBUG:speechbrain.utils.checkpoints:Registered checkpoint save hook for _save\n","DEBUG:speechbrain.utils.checkpoints:Registered checkpoint load hook for _recover\n","INFO:pytorch_lightning.utilities.migration.utils:Lightning automatically upgraded your loaded checkpoint from v1.5.4 to v2.5.2. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint ../root/.cache/torch/pyannote/models--pyannote--segmentation/snapshots/c4c8ceafcbb3a7a280c2d357aee9fbc9b0be7f9b/pytorch_model.bin`\n","INFO:speechbrain.utils.fetching:Fetch hyperparams.yaml: Using symlink found at '/root/.cache/torch/pyannote/speechbrain/hyperparams.yaml'\n","INFO:speechbrain.utils.fetching:Fetch custom.py: Fetching from HuggingFace Hub 'speechbrain/spkrec-ecapa-voxceleb' if not cached\n"]},{"output_type":"stream","name":"stdout","text":["Model was trained with pyannote.audio 0.0.1, yours is 3.3.2. Bad things might happen unless you revert pyannote.audio to 0.x.\n","Model was trained with torch 1.10.0+cu102, yours is 2.6.0+cu124. Bad things might happen unless you revert torch to 1.x.\n"]},{"output_type":"stream","name":"stderr","text":["DEBUG:speechbrain.utils.checkpoints:Registered checkpoint save hook for _save\n","DEBUG:speechbrain.utils.checkpoints:Registered checkpoint load hook for _load\n","DEBUG:speechbrain.utils.checkpoints:Registered parameter transfer hook for _load\n","/usr/local/lib/python3.11/dist-packages/speechbrain/utils/autocast.py:188: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n","  wrapped_fwd = torch.cuda.amp.custom_fwd(fwd, cast_inputs=cast_inputs)\n","DEBUG:speechbrain.utils.checkpoints:Registered checkpoint save hook for save\n","DEBUG:speechbrain.utils.checkpoints:Registered checkpoint load hook for load_if_possible\n","DEBUG:speechbrain.utils.parameter_transfer:Collecting files (or symlinks) for pretraining in /root/.cache/torch/pyannote/speechbrain.\n","INFO:speechbrain.utils.fetching:Fetch embedding_model.ckpt: Using symlink found at '/root/.cache/torch/pyannote/speechbrain/embedding_model.ckpt'\n","DEBUG:speechbrain.utils.parameter_transfer:Set local path in self.paths[\"embedding_model\"] = /root/.cache/torch/pyannote/speechbrain/embedding_model.ckpt\n","INFO:speechbrain.utils.fetching:Fetch mean_var_norm_emb.ckpt: Using symlink found at '/root/.cache/torch/pyannote/speechbrain/mean_var_norm_emb.ckpt'\n","DEBUG:speechbrain.utils.parameter_transfer:Set local path in self.paths[\"mean_var_norm_emb\"] = /root/.cache/torch/pyannote/speechbrain/mean_var_norm_emb.ckpt\n","INFO:speechbrain.utils.fetching:Fetch classifier.ckpt: Using symlink found at '/root/.cache/torch/pyannote/speechbrain/classifier.ckpt'\n","DEBUG:speechbrain.utils.parameter_transfer:Set local path in self.paths[\"classifier\"] = /root/.cache/torch/pyannote/speechbrain/classifier.ckpt\n","INFO:speechbrain.utils.fetching:Fetch label_encoder.txt: Using symlink found at '/root/.cache/torch/pyannote/speechbrain/label_encoder.ckpt'\n","DEBUG:speechbrain.utils.parameter_transfer:Set local path in self.paths[\"label_encoder\"] = /root/.cache/torch/pyannote/speechbrain/label_encoder.ckpt\n","INFO:speechbrain.utils.parameter_transfer:Loading pretrained files for: embedding_model, mean_var_norm_emb, classifier, label_encoder\n","DEBUG:speechbrain.utils.parameter_transfer:Redirecting (loading from local path): embedding_model -> /root/.cache/torch/pyannote/speechbrain/embedding_model.ckpt\n","DEBUG:speechbrain.utils.parameter_transfer:Redirecting (loading from local path): mean_var_norm_emb -> /root/.cache/torch/pyannote/speechbrain/mean_var_norm_emb.ckpt\n","DEBUG:speechbrain.utils.parameter_transfer:Redirecting (loading from local path): classifier -> /root/.cache/torch/pyannote/speechbrain/classifier.ckpt\n","DEBUG:speechbrain.utils.parameter_transfer:Redirecting (loading from local path): label_encoder -> /root/.cache/torch/pyannote/speechbrain/label_encoder.ckpt\n","DEBUG:speechbrain.dataio.encoder:Loaded categorical encoding from /root/.cache/torch/pyannote/speechbrain/label_encoder.ckpt\n","INFO:speechbrain.utils.fetching:Fetch hyperparams.yaml: Using symlink found at '/root/.cache/torch/pyannote/speechbrain/hyperparams.yaml'\n","INFO:speechbrain.utils.fetching:Fetch custom.py: Fetching from HuggingFace Hub 'speechbrain/spkrec-ecapa-voxceleb' if not cached\n","DEBUG:speechbrain.utils.parameter_transfer:Collecting files (or symlinks) for pretraining in /root/.cache/torch/pyannote/speechbrain.\n","INFO:speechbrain.utils.fetching:Fetch embedding_model.ckpt: Using symlink found at '/root/.cache/torch/pyannote/speechbrain/embedding_model.ckpt'\n","DEBUG:speechbrain.utils.parameter_transfer:Set local path in self.paths[\"embedding_model\"] = /root/.cache/torch/pyannote/speechbrain/embedding_model.ckpt\n","INFO:speechbrain.utils.fetching:Fetch mean_var_norm_emb.ckpt: Using symlink found at '/root/.cache/torch/pyannote/speechbrain/mean_var_norm_emb.ckpt'\n","DEBUG:speechbrain.utils.parameter_transfer:Set local path in self.paths[\"mean_var_norm_emb\"] = /root/.cache/torch/pyannote/speechbrain/mean_var_norm_emb.ckpt\n","INFO:speechbrain.utils.fetching:Fetch classifier.ckpt: Using symlink found at '/root/.cache/torch/pyannote/speechbrain/classifier.ckpt'\n","DEBUG:speechbrain.utils.parameter_transfer:Set local path in self.paths[\"classifier\"] = /root/.cache/torch/pyannote/speechbrain/classifier.ckpt\n","INFO:speechbrain.utils.fetching:Fetch label_encoder.txt: Using symlink found at '/root/.cache/torch/pyannote/speechbrain/label_encoder.ckpt'\n","DEBUG:speechbrain.utils.parameter_transfer:Set local path in self.paths[\"label_encoder\"] = /root/.cache/torch/pyannote/speechbrain/label_encoder.ckpt\n","INFO:speechbrain.utils.parameter_transfer:Loading pretrained files for: embedding_model, mean_var_norm_emb, classifier, label_encoder\n","DEBUG:speechbrain.utils.parameter_transfer:Redirecting (loading from local path): embedding_model -> /root/.cache/torch/pyannote/speechbrain/embedding_model.ckpt\n","DEBUG:speechbrain.utils.parameter_transfer:Redirecting (loading from local path): mean_var_norm_emb -> /root/.cache/torch/pyannote/speechbrain/mean_var_norm_emb.ckpt\n","DEBUG:speechbrain.utils.parameter_transfer:Redirecting (loading from local path): classifier -> /root/.cache/torch/pyannote/speechbrain/classifier.ckpt\n","DEBUG:speechbrain.utils.parameter_transfer:Redirecting (loading from local path): label_encoder -> /root/.cache/torch/pyannote/speechbrain/label_encoder.ckpt\n","DEBUG:speechbrain.dataio.encoder:Loaded categorical encoding from /root/.cache/torch/pyannote/speechbrain/label_encoder.ckpt\n"]}]},{"cell_type":"markdown","source":["### SOAP Gen"],"metadata":{"id":"n8Wf31nDtHbE"}},{"cell_type":"code","source":["fine_tune_path = '/content/drive/MyDrive/ClinicalNotesGen/Summarization/3_Fine_Tune_LLM'\n","model_name = 'pegasus' # ADJUST\n","sub_model_name = 'pegasus_xsum' # ADJUST\n","checkpoints_dir = f\"{fine_tune_path}/{model_name}/{sub_model_name}/lora_1\" # ADJUST\n","checkpoints_path = f\"{checkpoints_dir}/checkpoints\"\n","final_checkpoints_path = f\"{checkpoints_dir}/final_checkpoints\"\n","summary_path = f\"{checkpoints_dir}/summary\"\n","\n","print(f\"final_checkpoints_path: {final_checkpoints_path}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-TWm20SrtLpF","executionInfo":{"status":"ok","timestamp":1750750934486,"user_tz":-420,"elapsed":14,"user":{"displayName":"Unforgiven The","userId":"10817091228202119239"}},"outputId":"33c19898-1558-434d-9693-c9e8f143d839"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["final_checkpoints_path: /content/drive/MyDrive/ClinicalNotesGen/Summarization/3_Fine_Tune_LLM/pegasus/pegasus_xsum/lora_1/final_checkpoints\n"]}]},{"cell_type":"code","source":["# PeftConfig\n","perf_config = PeftConfig.from_pretrained(final_checkpoints_path)\n","\n","# Tokenizer\n","tok = AutoTokenizer.from_pretrained(final_checkpoints_path)\n","tok_fast   = PegasusTokenizerFast.from_pretrained(final_checkpoints_path)\n","\n","# FT model\n","ft_base = AutoModelForSeq2SeqLM.from_pretrained(perf_config.base_model_name_or_path, return_dict=True, device_map='auto')\n","ft_model = PeftModel.from_pretrained(ft_base, final_checkpoints_path)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":200,"referenced_widgets":["b4c774008fd843bcb3a616dd05b060f4","6a0e8f03675c477696301d59a02cce1f","3aae6d344fe0407c8ce8b3191ea18f27","30df408a2187415fbd09acfb1554f93e","906040d61942440b8e432c1f4bb261a4","958e4fed9bc64c7ba79f892307eacf0f","3c88eac49d08405e9f82216a8fafd437","d7d9bfd8d0694148b973eb375b8a7daa","f690674d9f2143d1a5cb51964d8f6e46","2dbf466d34224373a02e7159104d13a0","692fb6ca31084fabb4db1d341dca7fee","f3902c8ad8924c2a8ba2cbb3796e1eca","842d0e370aaf4968b772b3f1450134b0","69527697655e4e8282c3fd63b969f015","71711004ab924792b27302288e17ffa7","8cb4fd1dff294354ad65f0cde033caf2","bfeb7abfba5f4a498c53d79be933fb18","56c7a200208341c296a21970acbe2b31","37efdbf1bacc45d18dbec2cccd0234c0","101cea7215c84166992693340ffde0a2","c26d7db227744bd881278f521231c48a","9e80948db36b4b05ac9aa3ebd12c0956","7b0d4bc659ff402494b9b44c185200f2","be63090da6cb4e7cbdfdc61dd6a194fa","7583872aaef94da28e24047d32d64cda","2d30991682564dd899f2b9dc015170bd","3d0010c5bec34b7cb2e8996b05674db3","2868fbda9a704a3e969d20929974d8c0","37bbb6ff60b5412aae78a0a0ac592eab","df65aaca42d848d1a8b7b573ada2a301","94ad5def517648fcb2e1b73b8b17999d","9ff3922945144a16b6764aa2c4b65987","30cc89e84af048a885fa08972624e67e","1ad6bb8438ad4c18a09d97fa35aa15fd","3e6b7f62152c472e8290111f3a0be0cf","37cf33b5bacb44d6b03147b179679ba8","738197a427d64362b50d4a9634cf1719","4db7188de0924ecbaee66a9f5e15a96f","bb7504243f6a438d9120fae94021b486","3639fd57424a4b02822812c48ae44bd7","4f07eb0502b347489a5cc0e7e41194b8","3f8d4572768f4bbba012f50aeda80ab3","0eaafd390a8b47e2bde9455c385aaeaa","490db3eb4c074eb4973e8a533eb0a281"]},"id":"UcIBFkyktPm5","executionInfo":{"status":"ok","timestamp":1750750965702,"user_tz":-420,"elapsed":27987,"user":{"displayName":"Unforgiven The","userId":"10817091228202119239"}},"outputId":"7a4dd8a3-ca74-46ec-b397-4280629ff280"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["config.json:   0%|          | 0.00/1.39k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b4c774008fd843bcb3a616dd05b060f4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["pytorch_model.bin:   0%|          | 0.00/2.28G [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f3902c8ad8924c2a8ba2cbb3796e1eca"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["model.safetensors:   0%|          | 0.00/2.28G [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7b0d4bc659ff402494b9b44c185200f2"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some weights of PegasusForConditionalGeneration were not initialized from the model checkpoint at google/pegasus-xsum and are newly initialized: ['model.decoder.embed_positions.weight', 'model.encoder.embed_positions.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"display_data","data":{"text/plain":["generation_config.json:   0%|          | 0.00/259 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1ad6bb8438ad4c18a09d97fa35aa15fd"}},"metadata":{}}]},{"cell_type":"code","source":["MAX_SOURCE_LEN = 512\n","MAX_TARGET_LEN = 428\n","\n","gen_cfg = deepcopy(ft_model.generation_config)\n","gen_cfg.max_new_tokens = MAX_TARGET_LEN\n","gen_cfg.num_beams      = 1\n","gen_cfg.do_sample      = False\n","gen_cfg.early_stopping = False\n","\n","gen_cfg"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jAbk2MBFtR3U","executionInfo":{"status":"ok","timestamp":1750750965717,"user_tz":-420,"elapsed":11,"user":{"displayName":"Unforgiven The","userId":"10817091228202119239"}},"outputId":"59b8279a-d5b7-4f60-b0d1-e6a95c9d21d0"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["GenerationConfig {\n","  \"bos_token_id\": 0,\n","  \"decoder_start_token_id\": 0,\n","  \"eos_token_id\": 1,\n","  \"forced_eos_token_id\": 1,\n","  \"length_penalty\": 0.6,\n","  \"max_length\": 64,\n","  \"max_new_tokens\": 428,\n","  \"pad_token_id\": 0\n","}"]},"metadata":{},"execution_count":28}]},{"cell_type":"markdown","source":["# Main"],"metadata":{"id":"45FXhfZrFKOy"}},{"cell_type":"markdown","source":["- Input audio"],"metadata":{"id":"x6GI5mvQtchW"}},{"cell_type":"code","source":["def final_pipeline(name, fs, model_whisper, pipeline_diarization, doctor_keywords, patient_keywords):\n","    audio_path = f\"/content/drive/MyDrive/ClinicalNotesGen/Data/audios/en/wav/{name}.wav\"\n","    audio_id = upload_audio(fs, audio_path)\n","    print(\"audio_id:\", audio_id)\n","    transcript_word, transcript = process_audio(audio_path, model_whisper, pipeline_diarization)\n","    transcript_labelled = classify_speakers(transcript, doctor_keywords, patient_keywords)\n","    dialogue = transcript2string(transcript_labelled)\n","    summary = process_soap_traceability(dialogue, tok, tok_fast, ft_model)\n","    conversation_id = insert_conversation(db, name, audio_id, transcript, transcript_word, summary)\n","    print(\"Inserted conversation ID:\", conversation_id)"],"metadata":{"id":"d-weYkXv92hI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["name = 'fever_stomach'\n","final_pipeline(name, fs, model_whisper, pipeline_diarization, doctor_keywords, patient_keywords)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"ElT5L47UCftS","executionInfo":{"status":"ok","timestamp":1750753655620,"user_tz":-420,"elapsed":20584,"user":{"displayName":"Unforgiven The","userId":"10817091228202119239"}},"outputId":"972d878f-f8af-42c0-f02a-f5cc086c8c15"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["audio_id: 685a61637772f10be9ac8dd3\n"]},{"output_type":"stream","name":"stderr","text":["INFO:speechbrain.utils.fetching:Fetch hyperparams.yaml: Using symlink found at '/root/.cache/torch/pyannote/speechbrain/hyperparams.yaml'\n","INFO:speechbrain.utils.fetching:Fetch custom.py: Fetching from HuggingFace Hub 'speechbrain/spkrec-ecapa-voxceleb' if not cached\n","DEBUG:speechbrain.utils.parameter_transfer:Collecting files (or symlinks) for pretraining in /root/.cache/torch/pyannote/speechbrain.\n","INFO:speechbrain.utils.fetching:Fetch embedding_model.ckpt: Using symlink found at '/root/.cache/torch/pyannote/speechbrain/embedding_model.ckpt'\n","DEBUG:speechbrain.utils.parameter_transfer:Set local path in self.paths[\"embedding_model\"] = /root/.cache/torch/pyannote/speechbrain/embedding_model.ckpt\n","INFO:speechbrain.utils.fetching:Fetch mean_var_norm_emb.ckpt: Using symlink found at '/root/.cache/torch/pyannote/speechbrain/mean_var_norm_emb.ckpt'\n","DEBUG:speechbrain.utils.parameter_transfer:Set local path in self.paths[\"mean_var_norm_emb\"] = /root/.cache/torch/pyannote/speechbrain/mean_var_norm_emb.ckpt\n","INFO:speechbrain.utils.fetching:Fetch classifier.ckpt: Using symlink found at '/root/.cache/torch/pyannote/speechbrain/classifier.ckpt'\n","DEBUG:speechbrain.utils.parameter_transfer:Set local path in self.paths[\"classifier\"] = /root/.cache/torch/pyannote/speechbrain/classifier.ckpt\n","INFO:speechbrain.utils.fetching:Fetch label_encoder.txt: Using symlink found at '/root/.cache/torch/pyannote/speechbrain/label_encoder.ckpt'\n","DEBUG:speechbrain.utils.parameter_transfer:Set local path in self.paths[\"label_encoder\"] = /root/.cache/torch/pyannote/speechbrain/label_encoder.ckpt\n","INFO:speechbrain.utils.parameter_transfer:Loading pretrained files for: embedding_model, mean_var_norm_emb, classifier, label_encoder\n","DEBUG:speechbrain.utils.parameter_transfer:Redirecting (loading from local path): embedding_model -> /root/.cache/torch/pyannote/speechbrain/embedding_model.ckpt\n","DEBUG:speechbrain.utils.parameter_transfer:Redirecting (loading from local path): mean_var_norm_emb -> /root/.cache/torch/pyannote/speechbrain/mean_var_norm_emb.ckpt\n","DEBUG:speechbrain.utils.parameter_transfer:Redirecting (loading from local path): classifier -> /root/.cache/torch/pyannote/speechbrain/classifier.ckpt\n","DEBUG:speechbrain.utils.parameter_transfer:Redirecting (loading from local path): label_encoder -> /root/.cache/torch/pyannote/speechbrain/label_encoder.ckpt\n","DEBUG:speechbrain.dataio.encoder:Loaded categorical encoding from /root/.cache/torch/pyannote/speechbrain/label_encoder.ckpt\n","The following generation flags are not valid and may be ignored: ['length_penalty']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"]},{"output_type":"stream","name":"stdout","text":["[INFO] Generated summary length: 792 characters, 164 tokens\n","Inserted conversation ID: 685a61777772f10be9ac8ddd\n"]}]},{"cell_type":"code","source":["name = 'encounter_fever'\n","final_pipeline(name, fs, model_whisper, pipeline_diarization, doctor_keywords, patient_keywords)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"gBtgWtmL-qOK","executionInfo":{"status":"ok","timestamp":1750753471359,"user_tz":-420,"elapsed":15115,"user":{"displayName":"Unforgiven The","userId":"10817091228202119239"}},"outputId":"8618b8e8-748b-4387-ee76-b753f2658c49"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["audio_id: 685a60b07772f10be9ac8c82\n"]},{"output_type":"stream","name":"stderr","text":["INFO:speechbrain.utils.fetching:Fetch hyperparams.yaml: Using symlink found at '/root/.cache/torch/pyannote/speechbrain/hyperparams.yaml'\n","INFO:speechbrain.utils.fetching:Fetch custom.py: Fetching from HuggingFace Hub 'speechbrain/spkrec-ecapa-voxceleb' if not cached\n","DEBUG:speechbrain.utils.parameter_transfer:Collecting files (or symlinks) for pretraining in /root/.cache/torch/pyannote/speechbrain.\n","INFO:speechbrain.utils.fetching:Fetch embedding_model.ckpt: Using symlink found at '/root/.cache/torch/pyannote/speechbrain/embedding_model.ckpt'\n","DEBUG:speechbrain.utils.parameter_transfer:Set local path in self.paths[\"embedding_model\"] = /root/.cache/torch/pyannote/speechbrain/embedding_model.ckpt\n","INFO:speechbrain.utils.fetching:Fetch mean_var_norm_emb.ckpt: Using symlink found at '/root/.cache/torch/pyannote/speechbrain/mean_var_norm_emb.ckpt'\n","DEBUG:speechbrain.utils.parameter_transfer:Set local path in self.paths[\"mean_var_norm_emb\"] = /root/.cache/torch/pyannote/speechbrain/mean_var_norm_emb.ckpt\n","INFO:speechbrain.utils.fetching:Fetch classifier.ckpt: Using symlink found at '/root/.cache/torch/pyannote/speechbrain/classifier.ckpt'\n","DEBUG:speechbrain.utils.parameter_transfer:Set local path in self.paths[\"classifier\"] = /root/.cache/torch/pyannote/speechbrain/classifier.ckpt\n","INFO:speechbrain.utils.fetching:Fetch label_encoder.txt: Using symlink found at '/root/.cache/torch/pyannote/speechbrain/label_encoder.ckpt'\n","DEBUG:speechbrain.utils.parameter_transfer:Set local path in self.paths[\"label_encoder\"] = /root/.cache/torch/pyannote/speechbrain/label_encoder.ckpt\n","INFO:speechbrain.utils.parameter_transfer:Loading pretrained files for: embedding_model, mean_var_norm_emb, classifier, label_encoder\n","DEBUG:speechbrain.utils.parameter_transfer:Redirecting (loading from local path): embedding_model -> /root/.cache/torch/pyannote/speechbrain/embedding_model.ckpt\n","DEBUG:speechbrain.utils.parameter_transfer:Redirecting (loading from local path): mean_var_norm_emb -> /root/.cache/torch/pyannote/speechbrain/mean_var_norm_emb.ckpt\n","DEBUG:speechbrain.utils.parameter_transfer:Redirecting (loading from local path): classifier -> /root/.cache/torch/pyannote/speechbrain/classifier.ckpt\n","DEBUG:speechbrain.utils.parameter_transfer:Redirecting (loading from local path): label_encoder -> /root/.cache/torch/pyannote/speechbrain/label_encoder.ckpt\n","DEBUG:speechbrain.dataio.encoder:Loaded categorical encoding from /root/.cache/torch/pyannote/speechbrain/label_encoder.ckpt\n","The following generation flags are not valid and may be ignored: ['length_penalty']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"]},{"output_type":"stream","name":"stdout","text":["[INFO] Generated summary length: 719 characters, 153 tokens\n","Inserted conversation ID: 685a60bf7772f10be9ac8c8a\n"]}]},{"cell_type":"code","source":["name = 'abdominal_pain_history'\n","final_pipeline(name, fs, model_whisper, pipeline_diarization, doctor_keywords, patient_keywords)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"bWTrAE43Cvjh","executionInfo":{"status":"ok","timestamp":1750753828450,"user_tz":-420,"elapsed":172827,"user":{"displayName":"Unforgiven The","userId":"10817091228202119239"}},"outputId":"8575d9da-a4af-4867-b208-1142c031cb08"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["audio_id: 685a61777772f10be9ac8dde\n"]},{"output_type":"stream","name":"stderr","text":["INFO:speechbrain.utils.fetching:Fetch hyperparams.yaml: Using symlink found at '/root/.cache/torch/pyannote/speechbrain/hyperparams.yaml'\n","INFO:speechbrain.utils.fetching:Fetch custom.py: Fetching from HuggingFace Hub 'speechbrain/spkrec-ecapa-voxceleb' if not cached\n","DEBUG:speechbrain.utils.parameter_transfer:Collecting files (or symlinks) for pretraining in /root/.cache/torch/pyannote/speechbrain.\n","INFO:speechbrain.utils.fetching:Fetch embedding_model.ckpt: Using symlink found at '/root/.cache/torch/pyannote/speechbrain/embedding_model.ckpt'\n","DEBUG:speechbrain.utils.parameter_transfer:Set local path in self.paths[\"embedding_model\"] = /root/.cache/torch/pyannote/speechbrain/embedding_model.ckpt\n","INFO:speechbrain.utils.fetching:Fetch mean_var_norm_emb.ckpt: Using symlink found at '/root/.cache/torch/pyannote/speechbrain/mean_var_norm_emb.ckpt'\n","DEBUG:speechbrain.utils.parameter_transfer:Set local path in self.paths[\"mean_var_norm_emb\"] = /root/.cache/torch/pyannote/speechbrain/mean_var_norm_emb.ckpt\n","INFO:speechbrain.utils.fetching:Fetch classifier.ckpt: Using symlink found at '/root/.cache/torch/pyannote/speechbrain/classifier.ckpt'\n","DEBUG:speechbrain.utils.parameter_transfer:Set local path in self.paths[\"classifier\"] = /root/.cache/torch/pyannote/speechbrain/classifier.ckpt\n","INFO:speechbrain.utils.fetching:Fetch label_encoder.txt: Using symlink found at '/root/.cache/torch/pyannote/speechbrain/label_encoder.ckpt'\n","DEBUG:speechbrain.utils.parameter_transfer:Set local path in self.paths[\"label_encoder\"] = /root/.cache/torch/pyannote/speechbrain/label_encoder.ckpt\n","INFO:speechbrain.utils.parameter_transfer:Loading pretrained files for: embedding_model, mean_var_norm_emb, classifier, label_encoder\n","DEBUG:speechbrain.utils.parameter_transfer:Redirecting (loading from local path): embedding_model -> /root/.cache/torch/pyannote/speechbrain/embedding_model.ckpt\n","DEBUG:speechbrain.utils.parameter_transfer:Redirecting (loading from local path): mean_var_norm_emb -> /root/.cache/torch/pyannote/speechbrain/mean_var_norm_emb.ckpt\n","DEBUG:speechbrain.utils.parameter_transfer:Redirecting (loading from local path): classifier -> /root/.cache/torch/pyannote/speechbrain/classifier.ckpt\n","DEBUG:speechbrain.utils.parameter_transfer:Redirecting (loading from local path): label_encoder -> /root/.cache/torch/pyannote/speechbrain/label_encoder.ckpt\n","DEBUG:speechbrain.dataio.encoder:Loaded categorical encoding from /root/.cache/torch/pyannote/speechbrain/label_encoder.ckpt\n","The following generation flags are not valid and may be ignored: ['length_penalty']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"]},{"output_type":"stream","name":"stdout","text":["[INFO] Generated summary length: 1055 characters, 219 tokens\n","Inserted conversation ID: 685a62247772f10be9ac8f4b\n"]}]},{"cell_type":"code","source":["name = 'sexual_health_history'\n","final_pipeline(name, fs, model_whisper, pipeline_diarization, doctor_keywords, patient_keywords)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":706},"collapsed":true,"id":"-ncZKKIoC11R","executionInfo":{"status":"error","timestamp":1750754044079,"user_tz":-420,"elapsed":215625,"user":{"displayName":"Unforgiven The","userId":"10817091228202119239"}},"outputId":"e07caf8b-4d95-4ccd-83ed-caf5e84f9482"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["audio_id: 685a62247772f10be9ac8f4c\n"]},{"output_type":"stream","name":"stderr","text":["INFO:speechbrain.utils.fetching:Fetch hyperparams.yaml: Using symlink found at '/root/.cache/torch/pyannote/speechbrain/hyperparams.yaml'\n","INFO:speechbrain.utils.fetching:Fetch custom.py: Fetching from HuggingFace Hub 'speechbrain/spkrec-ecapa-voxceleb' if not cached\n","DEBUG:speechbrain.utils.parameter_transfer:Collecting files (or symlinks) for pretraining in /root/.cache/torch/pyannote/speechbrain.\n","INFO:speechbrain.utils.fetching:Fetch embedding_model.ckpt: Using symlink found at '/root/.cache/torch/pyannote/speechbrain/embedding_model.ckpt'\n","DEBUG:speechbrain.utils.parameter_transfer:Set local path in self.paths[\"embedding_model\"] = /root/.cache/torch/pyannote/speechbrain/embedding_model.ckpt\n","INFO:speechbrain.utils.fetching:Fetch mean_var_norm_emb.ckpt: Using symlink found at '/root/.cache/torch/pyannote/speechbrain/mean_var_norm_emb.ckpt'\n","DEBUG:speechbrain.utils.parameter_transfer:Set local path in self.paths[\"mean_var_norm_emb\"] = /root/.cache/torch/pyannote/speechbrain/mean_var_norm_emb.ckpt\n","INFO:speechbrain.utils.fetching:Fetch classifier.ckpt: Using symlink found at '/root/.cache/torch/pyannote/speechbrain/classifier.ckpt'\n","DEBUG:speechbrain.utils.parameter_transfer:Set local path in self.paths[\"classifier\"] = /root/.cache/torch/pyannote/speechbrain/classifier.ckpt\n","INFO:speechbrain.utils.fetching:Fetch label_encoder.txt: Using symlink found at '/root/.cache/torch/pyannote/speechbrain/label_encoder.ckpt'\n","DEBUG:speechbrain.utils.parameter_transfer:Set local path in self.paths[\"label_encoder\"] = /root/.cache/torch/pyannote/speechbrain/label_encoder.ckpt\n","INFO:speechbrain.utils.parameter_transfer:Loading pretrained files for: embedding_model, mean_var_norm_emb, classifier, label_encoder\n","DEBUG:speechbrain.utils.parameter_transfer:Redirecting (loading from local path): embedding_model -> /root/.cache/torch/pyannote/speechbrain/embedding_model.ckpt\n","DEBUG:speechbrain.utils.parameter_transfer:Redirecting (loading from local path): mean_var_norm_emb -> /root/.cache/torch/pyannote/speechbrain/mean_var_norm_emb.ckpt\n","DEBUG:speechbrain.utils.parameter_transfer:Redirecting (loading from local path): classifier -> /root/.cache/torch/pyannote/speechbrain/classifier.ckpt\n","DEBUG:speechbrain.utils.parameter_transfer:Redirecting (loading from local path): label_encoder -> /root/.cache/torch/pyannote/speechbrain/label_encoder.ckpt\n","DEBUG:speechbrain.dataio.encoder:Loaded categorical encoding from /root/.cache/torch/pyannote/speechbrain/label_encoder.ckpt\n","The following generation flags are not valid and may be ignored: ['length_penalty']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"]},{"output_type":"stream","name":"stdout","text":["[INFO] Generated summary length: 1388 characters, 252 tokens\n"]},{"output_type":"error","ename":"OperationFailure","evalue":"you are over your space quota, using 525 MB of 512 MB, full error: {'ok': 0, 'errmsg': 'you are over your space quota, using 525 MB of 512 MB', 'code': 8000, 'codeName': 'AtlasError'}","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mOperationFailure\u001b[0m                          Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-72-981731416.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'sexual_health_history'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mfinal_pipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_whisper\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpipeline_diarization\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdoctor_keywords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatient_keywords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/tmp/ipython-input-65-2584181200.py\u001b[0m in \u001b[0;36mfinal_pipeline\u001b[0;34m(name, fs, model_whisper, pipeline_diarization, doctor_keywords, patient_keywords)\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mdialogue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtranscript2string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtranscript_labelled\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0msummary\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocess_soap_traceability\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdialogue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtok\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtok_fast\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mft_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mconversation_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minsert_conversation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maudio_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtranscript\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtranscript_word\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msummary\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Inserted conversation ID:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconversation_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipython-input-64-2770939494.py\u001b[0m in \u001b[0;36minsert_conversation\u001b[0;34m(db, name, audio_id, transcript, word_transcript, summary)\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;34m\"summary\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0msummary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     }\n\u001b[0;32m---> 27\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdb\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"conversation\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minsert_one\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconversation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minserted_id\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pymongo/synchronous/collection.py\u001b[0m in \u001b[0;36minsert_one\u001b[0;34m(self, document, bypass_document_validation, session, comment)\u001b[0m\n\u001b[1;32m    889\u001b[0m         \u001b[0mwrite_concern\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_write_concern_for\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    890\u001b[0m         return InsertOneResult(\n\u001b[0;32m--> 891\u001b[0;31m             self._insert_one(\n\u001b[0m\u001b[1;32m    892\u001b[0m                 \u001b[0mdocument\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    893\u001b[0m                 \u001b[0mordered\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pymongo/synchronous/collection.py\u001b[0m in \u001b[0;36m_insert_one\u001b[0;34m(self, doc, ordered, write_concern, op_id, bypass_doc_val, session, comment)\u001b[0m\n\u001b[1;32m    829\u001b[0m             \u001b[0m_check_write_command_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 831\u001b[0;31m         self._database.client._retryable_write(\n\u001b[0m\u001b[1;32m    832\u001b[0m             \u001b[0macknowledged\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_insert_command\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moperation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_Op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mINSERT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    833\u001b[0m         )\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pymongo/synchronous/mongo_client.py\u001b[0m in \u001b[0;36m_retryable_write\u001b[0;34m(self, retryable, func, session, operation, bulk, operation_id)\u001b[0m\n\u001b[1;32m   2059\u001b[0m         \"\"\"\n\u001b[1;32m   2060\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tmp_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2061\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_retry_with_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretryable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbulk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moperation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moperation_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2062\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2063\u001b[0m     def _cleanup_cursor_no_lock(\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pymongo/synchronous/mongo_client.py\u001b[0m in \u001b[0;36m_retry_with_session\u001b[0;34m(self, retryable, func, session, bulk, operation, operation_id)\u001b[0m\n\u001b[1;32m   1945\u001b[0m             \u001b[0mretryable\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretry_writes\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0msession\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0min_transaction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1946\u001b[0m         )\n\u001b[0;32m-> 1947\u001b[0;31m         return self._retry_internal(\n\u001b[0m\u001b[1;32m   1948\u001b[0m             \u001b[0mfunc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1949\u001b[0m             \u001b[0msession\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pymongo/_csot.py\u001b[0m in \u001b[0;36mcsot_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    123\u001b[0m                     \u001b[0;32mwith\u001b[0m \u001b[0m_TimeoutContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m                         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcsot_wrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pymongo/synchronous/mongo_client.py\u001b[0m in \u001b[0;36m_retry_internal\u001b[0;34m(self, func, session, bulk, operation, is_read, address, read_pref, retryable, operation_id)\u001b[0m\n\u001b[1;32m   1991\u001b[0m             \u001b[0mretryable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretryable\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1992\u001b[0m             \u001b[0moperation_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moperation_id\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1993\u001b[0;31m         ).run()\n\u001b[0m\u001b[1;32m   1994\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1995\u001b[0m     def _retryable_read(\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pymongo/synchronous/mongo_client.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2728\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_last_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheck_csot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2729\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2730\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_read\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_write\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2731\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mServerSelectionTimeoutError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2732\u001b[0m                 \u001b[0;31m# The application may think the write was never attempted\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pymongo/synchronous/mongo_client.py\u001b[0m in \u001b[0;36m_write\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2860\u001b[0m                         \u001b[0moperationId\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_operation_id\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2861\u001b[0m                     )\n\u001b[0;32m-> 2862\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_retryable\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2863\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mPyMongoError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2864\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_retryable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pymongo/synchronous/collection.py\u001b[0m in \u001b[0;36m_insert_command\u001b[0;34m(session, conn, retryable_write)\u001b[0m\n\u001b[1;32m    817\u001b[0m                 \u001b[0mcommand\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"bypassDocumentValidation\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbypass_doc_val\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 819\u001b[0;31m             result = conn.command(\n\u001b[0m\u001b[1;32m    820\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_database\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m                 \u001b[0mcommand\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pymongo/synchronous/helpers.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mOperationFailure\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mno_reauth\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pymongo/synchronous/pool.py\u001b[0m in \u001b[0;36mcommand\u001b[0;34m(self, dbname, spec, read_preference, codec_options, check, allowable_errors, read_concern, write_concern, parse_write_concern_error, collation, session, client, retryable_write, publish_events, user_fields, exhaust_allowed)\u001b[0m\n\u001b[1;32m    412\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_raise_if_not_writable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munacknowledged\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    413\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 414\u001b[0;31m             return command(\n\u001b[0m\u001b[1;32m    415\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    416\u001b[0m                 \u001b[0mdbname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pymongo/synchronous/network.py\u001b[0m in \u001b[0;36mcommand\u001b[0;34m(conn, dbname, spec, is_mongos, read_preference, codec_options, session, client, check, allowable_errors, address, listeners, max_bson_size, read_concern, parse_write_concern_error, collation, compression_ctx, use_op_msg, unacknowledged, user_fields, exhaust_allowed, write_concern)\u001b[0m\n\u001b[1;32m    210\u001b[0m                 \u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse_doc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mcheck\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 212\u001b[0;31m                 helpers_shared._check_command_response(\n\u001b[0m\u001b[1;32m    213\u001b[0m                     \u001b[0mresponse_doc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m                     \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_wire_version\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pymongo/helpers_shared.py\u001b[0m in \u001b[0;36m_check_command_response\u001b[0;34m(response, max_wire_version, allowable_errors, parse_write_concern_error)\u001b[0m\n\u001b[1;32m    248\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mCursorNotFound\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merrmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_wire_version\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 250\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mOperationFailure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merrmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_wire_version\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    251\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mOperationFailure\u001b[0m: you are over your space quota, using 525 MB of 512 MB, full error: {'ok': 0, 'errmsg': 'you are over your space quota, using 525 MB of 512 MB', 'code': 8000, 'codeName': 'AtlasError'}"]}]},{"cell_type":"code","source":["name = 'encounter_chest_pain'\n","final_pipeline(name, fs, model_whisper, pipeline_diarization, doctor_keywords, patient_keywords)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"Yq053EpuA8kF","executionInfo":{"status":"ok","timestamp":1750753313307,"user_tz":-420,"elapsed":126449,"user":{"displayName":"Unforgiven The","userId":"10817091228202119239"}},"outputId":"60658d4d-a375-4849-b474-643bd5dddeae"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["audio_id: 685a5fa27772f10be9ac8c56\n"]},{"output_type":"stream","name":"stderr","text":["INFO:speechbrain.utils.fetching:Fetch hyperparams.yaml: Using symlink found at '/root/.cache/torch/pyannote/speechbrain/hyperparams.yaml'\n","INFO:speechbrain.utils.fetching:Fetch custom.py: Fetching from HuggingFace Hub 'speechbrain/spkrec-ecapa-voxceleb' if not cached\n","DEBUG:speechbrain.utils.parameter_transfer:Collecting files (or symlinks) for pretraining in /root/.cache/torch/pyannote/speechbrain.\n","INFO:speechbrain.utils.fetching:Fetch embedding_model.ckpt: Using symlink found at '/root/.cache/torch/pyannote/speechbrain/embedding_model.ckpt'\n","DEBUG:speechbrain.utils.parameter_transfer:Set local path in self.paths[\"embedding_model\"] = /root/.cache/torch/pyannote/speechbrain/embedding_model.ckpt\n","INFO:speechbrain.utils.fetching:Fetch mean_var_norm_emb.ckpt: Using symlink found at '/root/.cache/torch/pyannote/speechbrain/mean_var_norm_emb.ckpt'\n","DEBUG:speechbrain.utils.parameter_transfer:Set local path in self.paths[\"mean_var_norm_emb\"] = /root/.cache/torch/pyannote/speechbrain/mean_var_norm_emb.ckpt\n","INFO:speechbrain.utils.fetching:Fetch classifier.ckpt: Using symlink found at '/root/.cache/torch/pyannote/speechbrain/classifier.ckpt'\n","DEBUG:speechbrain.utils.parameter_transfer:Set local path in self.paths[\"classifier\"] = /root/.cache/torch/pyannote/speechbrain/classifier.ckpt\n","INFO:speechbrain.utils.fetching:Fetch label_encoder.txt: Using symlink found at '/root/.cache/torch/pyannote/speechbrain/label_encoder.ckpt'\n","DEBUG:speechbrain.utils.parameter_transfer:Set local path in self.paths[\"label_encoder\"] = /root/.cache/torch/pyannote/speechbrain/label_encoder.ckpt\n","INFO:speechbrain.utils.parameter_transfer:Loading pretrained files for: embedding_model, mean_var_norm_emb, classifier, label_encoder\n","DEBUG:speechbrain.utils.parameter_transfer:Redirecting (loading from local path): embedding_model -> /root/.cache/torch/pyannote/speechbrain/embedding_model.ckpt\n","DEBUG:speechbrain.utils.parameter_transfer:Redirecting (loading from local path): mean_var_norm_emb -> /root/.cache/torch/pyannote/speechbrain/mean_var_norm_emb.ckpt\n","DEBUG:speechbrain.utils.parameter_transfer:Redirecting (loading from local path): classifier -> /root/.cache/torch/pyannote/speechbrain/classifier.ckpt\n","DEBUG:speechbrain.utils.parameter_transfer:Redirecting (loading from local path): label_encoder -> /root/.cache/torch/pyannote/speechbrain/label_encoder.ckpt\n","DEBUG:speechbrain.dataio.encoder:Loaded categorical encoding from /root/.cache/torch/pyannote/speechbrain/label_encoder.ckpt\n","The following generation flags are not valid and may be ignored: ['length_penalty']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"]},{"output_type":"stream","name":"stdout","text":["[INFO] Generated summary length: 1137 characters, 223 tokens\n","Inserted conversation ID: 685a60217772f10be9ac8c81\n"]}]},{"cell_type":"code","source":["name = 'type_2_diabetes'\n","final_pipeline(name, fs, model_whisper, pipeline_diarization, doctor_keywords, patient_keywords)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YqngOlBS-7AH","executionInfo":{"status":"ok","timestamp":1750753607594,"user_tz":-420,"elapsed":136233,"user":{"displayName":"Unforgiven The","userId":"10817091228202119239"}},"outputId":"9cc35ba1-4868-410a-f14e-e97b6ae695ce"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["audio_id: 685a60bf7772f10be9ac8c8b\n"]},{"output_type":"stream","name":"stderr","text":["INFO:speechbrain.utils.fetching:Fetch hyperparams.yaml: Using symlink found at '/root/.cache/torch/pyannote/speechbrain/hyperparams.yaml'\n","INFO:speechbrain.utils.fetching:Fetch custom.py: Fetching from HuggingFace Hub 'speechbrain/spkrec-ecapa-voxceleb' if not cached\n","DEBUG:speechbrain.utils.parameter_transfer:Collecting files (or symlinks) for pretraining in /root/.cache/torch/pyannote/speechbrain.\n","INFO:speechbrain.utils.fetching:Fetch embedding_model.ckpt: Using symlink found at '/root/.cache/torch/pyannote/speechbrain/embedding_model.ckpt'\n","DEBUG:speechbrain.utils.parameter_transfer:Set local path in self.paths[\"embedding_model\"] = /root/.cache/torch/pyannote/speechbrain/embedding_model.ckpt\n","INFO:speechbrain.utils.fetching:Fetch mean_var_norm_emb.ckpt: Using symlink found at '/root/.cache/torch/pyannote/speechbrain/mean_var_norm_emb.ckpt'\n","DEBUG:speechbrain.utils.parameter_transfer:Set local path in self.paths[\"mean_var_norm_emb\"] = /root/.cache/torch/pyannote/speechbrain/mean_var_norm_emb.ckpt\n","INFO:speechbrain.utils.fetching:Fetch classifier.ckpt: Using symlink found at '/root/.cache/torch/pyannote/speechbrain/classifier.ckpt'\n","DEBUG:speechbrain.utils.parameter_transfer:Set local path in self.paths[\"classifier\"] = /root/.cache/torch/pyannote/speechbrain/classifier.ckpt\n","INFO:speechbrain.utils.fetching:Fetch label_encoder.txt: Using symlink found at '/root/.cache/torch/pyannote/speechbrain/label_encoder.ckpt'\n","DEBUG:speechbrain.utils.parameter_transfer:Set local path in self.paths[\"label_encoder\"] = /root/.cache/torch/pyannote/speechbrain/label_encoder.ckpt\n","INFO:speechbrain.utils.parameter_transfer:Loading pretrained files for: embedding_model, mean_var_norm_emb, classifier, label_encoder\n","DEBUG:speechbrain.utils.parameter_transfer:Redirecting (loading from local path): embedding_model -> /root/.cache/torch/pyannote/speechbrain/embedding_model.ckpt\n","DEBUG:speechbrain.utils.parameter_transfer:Redirecting (loading from local path): mean_var_norm_emb -> /root/.cache/torch/pyannote/speechbrain/mean_var_norm_emb.ckpt\n","DEBUG:speechbrain.utils.parameter_transfer:Redirecting (loading from local path): classifier -> /root/.cache/torch/pyannote/speechbrain/classifier.ckpt\n","DEBUG:speechbrain.utils.parameter_transfer:Redirecting (loading from local path): label_encoder -> /root/.cache/torch/pyannote/speechbrain/label_encoder.ckpt\n","DEBUG:speechbrain.dataio.encoder:Loaded categorical encoding from /root/.cache/torch/pyannote/speechbrain/label_encoder.ckpt\n","The following generation flags are not valid and may be ignored: ['length_penalty']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"]},{"output_type":"stream","name":"stdout","text":["[INFO] Generated summary length: 1174 characters, 220 tokens\n","Inserted conversation ID: 685a61477772f10be9ac8dd2\n"]}]},{"cell_type":"code","source":["# name = 'encounter_joint_pain'\n","# final_pipeline(name, fs, model_whisper, pipeline_diarization, doctor_keywords, patient_keywords)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":636},"collapsed":true,"id":"tb3cIllE-qC0","executionInfo":{"status":"error","timestamp":1750753127235,"user_tz":-420,"elapsed":106047,"user":{"displayName":"Unforgiven The","userId":"10817091228202119239"}},"outputId":"7c0baacd-cb8e-43a3-e48b-653ce6f9b70f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["audio_id: 685a5efd7772f10be9ac8c35\n"]},{"output_type":"stream","name":"stderr","text":["INFO:speechbrain.utils.fetching:Fetch hyperparams.yaml: Using symlink found at '/root/.cache/torch/pyannote/speechbrain/hyperparams.yaml'\n","INFO:speechbrain.utils.fetching:Fetch custom.py: Fetching from HuggingFace Hub 'speechbrain/spkrec-ecapa-voxceleb' if not cached\n","DEBUG:speechbrain.utils.parameter_transfer:Collecting files (or symlinks) for pretraining in /root/.cache/torch/pyannote/speechbrain.\n","INFO:speechbrain.utils.fetching:Fetch embedding_model.ckpt: Using symlink found at '/root/.cache/torch/pyannote/speechbrain/embedding_model.ckpt'\n","DEBUG:speechbrain.utils.parameter_transfer:Set local path in self.paths[\"embedding_model\"] = /root/.cache/torch/pyannote/speechbrain/embedding_model.ckpt\n","INFO:speechbrain.utils.fetching:Fetch mean_var_norm_emb.ckpt: Using symlink found at '/root/.cache/torch/pyannote/speechbrain/mean_var_norm_emb.ckpt'\n","DEBUG:speechbrain.utils.parameter_transfer:Set local path in self.paths[\"mean_var_norm_emb\"] = /root/.cache/torch/pyannote/speechbrain/mean_var_norm_emb.ckpt\n","INFO:speechbrain.utils.fetching:Fetch classifier.ckpt: Using symlink found at '/root/.cache/torch/pyannote/speechbrain/classifier.ckpt'\n","DEBUG:speechbrain.utils.parameter_transfer:Set local path in self.paths[\"classifier\"] = /root/.cache/torch/pyannote/speechbrain/classifier.ckpt\n","INFO:speechbrain.utils.fetching:Fetch label_encoder.txt: Using symlink found at '/root/.cache/torch/pyannote/speechbrain/label_encoder.ckpt'\n","DEBUG:speechbrain.utils.parameter_transfer:Set local path in self.paths[\"label_encoder\"] = /root/.cache/torch/pyannote/speechbrain/label_encoder.ckpt\n","INFO:speechbrain.utils.parameter_transfer:Loading pretrained files for: embedding_model, mean_var_norm_emb, classifier, label_encoder\n","DEBUG:speechbrain.utils.parameter_transfer:Redirecting (loading from local path): embedding_model -> /root/.cache/torch/pyannote/speechbrain/embedding_model.ckpt\n","DEBUG:speechbrain.utils.parameter_transfer:Redirecting (loading from local path): mean_var_norm_emb -> /root/.cache/torch/pyannote/speechbrain/mean_var_norm_emb.ckpt\n","DEBUG:speechbrain.utils.parameter_transfer:Redirecting (loading from local path): classifier -> /root/.cache/torch/pyannote/speechbrain/classifier.ckpt\n","DEBUG:speechbrain.utils.parameter_transfer:Redirecting (loading from local path): label_encoder -> /root/.cache/torch/pyannote/speechbrain/label_encoder.ckpt\n","DEBUG:speechbrain.dataio.encoder:Loaded categorical encoding from /root/.cache/torch/pyannote/speechbrain/label_encoder.ckpt\n"]},{"output_type":"error","ename":"ValueError","evalue":"max() arg is an empty sequence","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-66-1859537803.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'encounter_joint_pain'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mfinal_pipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_whisper\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpipeline_diarization\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdoctor_keywords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatient_keywords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/tmp/ipython-input-65-2584181200.py\u001b[0m in \u001b[0;36mfinal_pipeline\u001b[0;34m(name, fs, model_whisper, pipeline_diarization, doctor_keywords, patient_keywords)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mtranscript_labelled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclassify_speakers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtranscript\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdoctor_keywords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatient_keywords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mdialogue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtranscript2string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtranscript_labelled\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0msummary\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocess_soap_traceability\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdialogue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtok\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtok_fast\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mft_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0mconversation_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minsert_conversation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maudio_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtranscript\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtranscript_word\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msummary\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Inserted conversation ID:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconversation_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipython-input-22-3175558134.py\u001b[0m in \u001b[0;36mprocess_soap_traceability\u001b[0;34m(dialogue, tok, tok_fast, ft_model)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menc_tokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m         \u001b[0mj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mj\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mutt_starts\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m         \u001b[0mtoken_to_utt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mutterance_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: max() arg is an empty sequence"]}]},{"cell_type":"markdown","source":[],"metadata":{"id":"-hDAV-93_Jem"}},{"cell_type":"markdown","source":["# Testing"],"metadata":{"id":"knUs-tHr_Mkl"}},{"cell_type":"markdown","source":["### Retrieve conversation"],"metadata":{"id":"0P60WeNv_Qxl"}},{"cell_type":"code","source":["conversation_id = \"685a61477772f10be9ac8dd2\"\n","record = get_conversation(db, str(conversation_id))\n","audio_binary = get_audio(fs, record[\"audio_id\"])"],"metadata":{"id":"5V-w0Dgs_WVH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["Audio(data=audio_binary, autoplay=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":76,"output_embedded_package_id":"17d1K6ndPJuAn5F-QvFH5hEuprLaG902R"},"id":"iHRgW7weF2um","executionInfo":{"status":"ok","timestamp":1750754441358,"user_tz":-420,"elapsed":23843,"user":{"displayName":"Unforgiven The","userId":"10817091228202119239"}},"outputId":"411ce481-daf6-48ea-c111-8cb37beda6f3"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"code","source":["record[\"summary\"]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"r852G5sx_t22","executionInfo":{"status":"ok","timestamp":1750754453252,"user_tz":-420,"elapsed":8,"user":{"displayName":"Unforgiven The","userId":"10817091228202119239"}},"outputId":"921c0ce2-2c02-4901-bf6a-6b72887934fd"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'utterances': {'U1': \"Doctor: Hi there, my name's Leah, I'm one of the junior doctors working in the GP surgery. Is it okay if I just check your name and date of birth please? Yeah,\",\n","  'U2': \"Patient: so it's Camilla, Camilla Weldon, and it's the 3rd of May 1977. Nice to meet you. Is it okay if I call you Camilla today? Yeah, of course. Fabulous.\",\n","  'U3': 'Doctor: So how can I help you today Camilla?',\n","  'U4': 'Patient: Yeah, so the doctor I saw last week, he rang me yesterday to say that I had some blood tests and he just said that the blood tests said I had diabetes. So it was just to come and have a chat to you about, really about that. Okay,',\n","  'U5': 'Doctor: so how are you feeling about being told that news over the phone?',\n","  'U6': \"Patient: To be honest, I was relieved because at least I sort of now know what's going on.\",\n","  'U7': \"Patient: But I have to say I'm a little bit anxious because I don't know a lot about diabetes but I'm not sure what's going on. I know that it is caused by lack of exercise and not eating very well and I've got a lot of work to do if that's the case. Okay,\",\n","  'U8': 'Doctor: and was there anything that you were particularly worried about that we might be talking about today?',\n","  'U9': \"Patient: Yeah, it's just, so my colleague at work had mentioned that he has to have quite regular tests for his eyes and he's got to have a lot of blood tests. But also for his feet. And he talks about long -termly it could lead to him losing sensation in his feet but also him losing his eyesight and that really does obviously worry me.\",\n","  'U10': \"Doctor: Is that something you'd like to talk a bit more about today? Yeah, if\",\n","  'U11': \"Patient: you've got the time, yeah. Okay,\",\n","  'U12': \"Doctor: okay, not to worry. So I think to start off with it would be helpful if I could understand a little bit about your general health and a bit about some of the lifestyle factors that you mentioned, maybe a bit of work to do with. Okay. Just so I can understand sort of where you're coming from and how we can advise you with some help in managing the diabetes. Is that okay? Thank you, yes, yes. Okay, so what symptoms did you come in with initially? I know you mentioned you felt a bit tired but what kind of things were you experiencing when you saw the GP to start with?\",\n","  'U13': 'Patient: I was feeling tired and just quite washed out. Okay. But over a few months I had had, sort of like thrush and some urine infections so I did mention that to the doctor as well. Okay, and was',\n","  'U14': 'Doctor: that unusual for you to have those infections? Yeah. Okay.',\n","  'U15': \"Doctor: Thank you for that, it's been helpful to understand a little bit about your kind of health in general. That's okay. A bit more about you. Hopefully that will help us give some more information in terms of the diabetes. So I suppose we just need to talk a little bit more about the diabetes itself and what that actually means for you. Yeah. So in people who don't have diabetes, what happens when you eat food is it's broken down into sugar molecules called glucose. And that sugar goes round and round the body to places where it's needed to be used.\",\n","  'U16': \"Doctor: And in order to store the glucose in the cells where we need to use it, there's a hormone called insulin. Have you heard of that before? I have heard of it, yes. Okay. So insulin's job is to move sugar from the blood into cells and to store it to be used for later.\",\n","  'U17': \"Doctor: So what happens in diabetes is because there's lots and lots of sugar going round all of the time, the body stops really recognising that there's sugar there. It almost becomes normal for the sugar. It's not going to be that high. So the body stops making as much insulin because it doesn't think it needs to move that sugar into the cells. Another thing that can happen is because there's so much sugar being moved all the time into the cells, the cells sort of stop paying attention to insulin anyway. So even if we do make some insulin, it doesn't really do its job properly anymore. Wow. Does that make sense? Yeah. Okay. Are you happy if I just kind of ask you to summarise what we've just gone through just to make sure I've explained it properly? Me too. I'll do my best.\",\n","  'U18': \"Patient: But what I understand is that so we eat food and it gets broken down to sugar, glucose in the blood, and that's carried by insulin to cells that need the sugar to do their functions. But diabetes, we have too much sugar in the blood, and something happens. Something happens to the body and that becomes the normal for the body. So it doesn't really think it's got too much. So it's producing less insulin. So insulin obviously is not there to move it. But then also it affects the cells. The cells suddenly just don't pay any attention to insulin. So they just don't even accept any of the sugar. Hence, that buildup is there.\",\n","  'U19': \"Doctor: So it's the sugar being high in the blood that causes the problems, some of the problems that it sounds like your colleague might be experiencing. So we can think about the complications of diabetes in sort of a short term and then a longer term kind of time period. Okay. So some of the short term problems that patients with diabetes commonly experience are infections. So when you mentioned earlier about the water infections in the fresh. Yes. Yes. It may be that that was to do with the fact that you were on a diet. Yes. And you had quite high blood sugars at the time. Oh\",\n","  'U20': 'Patient: my goodness. Okay. Yeah. Yeah. So',\n","  'U21': \"Doctor: what happens when there's lots of sugar in the blood is the kidneys filter the blood and some of that sugar gets into the urine, which means that bacteria which love sugar can use that sugar to grow and cause the infections. Infections. Okay. Okay. Mm -hmm. Mm -hmm. And then when we move on to thinking about the longer term complications, it causes problems because the glucose going round and round in the blood damages the blood vessels. So there's a selection of small blood vessels and some bigger blood vessels that that causes problems for. So in the small blood vessels, they're the blood vessels that are found behind the eyes and the blood vessels that supply the nerves to the fingers and toes. And also the blood vessels in the kidneys are quite small as well. Okay. So when you mentioned earlier about your colleague getting his eyes checked and his feet checked to check he could still feel things properly. That's probably to make sure that he wasn't getting those complications of diabetes. I\",\n","  'U22': 'Patient: understand. It makes sense. Yes. Thank you. Thank you.',\n","  'U23': \"Doctor: And then the other things are sort of in the bigger blood vessels. So there's some quite big blood vessels in the brain and there's some big blood vessels in the heart as well. So if those blood vessels get damaged, they can cause things like strokes and problems with the heart, so heart disease and heart attacks potentially. So hopefully we can talk through how we can manage the condition a little bit better today. And try and reduce those risks as much as possible. Yes. Of course. Of course. Does that make sense so far? Yeah.\",\n","  'U24': \"Patient: I think that's, yeah, it does make sense. Thank you. Thank you.\",\n","  'U25': \"Doctor: Thank you. What I'll do is I'll give you a few leaflets for you to take away as well so you can have a little read between now and when you're next to see us. Okay. And if you've got any questions, please just give us a call or you can book in to speak to one of the GPs again.\",\n","  'U26': 'Patient: Thank you so much. Thank you. All right. Lovely to meet you. Thank you. You too. Thank you for your time. Thank you.'},\n"," 'S': [{'sentence_idx': '0',\n","   'sentence_text': 'The patient, a female, reports feeling tired and anxious, with no knowledge of diabetes.',\n","   'utterance_id': 'U1'},\n","  {'sentence_idx': '1',\n","   'sentence_text': 'She was diagnosed with diabetes over the phone last week.',\n","   'utterance_id': 'U4'},\n","  {'sentence_idx': '2',\n","   'sentence_text': 'She has a history of diabetes and is concerned about the impact on her eyes and feet.',\n","   'utterance_id': 'U7'}],\n"," 'O': [{'sentence_idx': '0',\n","   'sentence_text': 'Initial symptoms included fatigue and feeling tired.',\n","   'utterance_id': 'U26'},\n","  {'sentence_idx': '1',\n","   'sentence_text': 'The patient was diagnosed with diabetes due to lack of exercise and poor eating habits.',\n","   'utterance_id': 'U7'},\n","  {'sentence_idx': '2',\n","   'sentence_text': \"The patient's symptoms were initially reported as fatigue and feeling tired.\",\n","   'utterance_id': 'U26'}],\n"," 'A': [{'sentence_idx': '0',\n","   'sentence_text': 'The primary diagnosis is diabetes, with potential implications for eye and foot symptoms.',\n","   'utterance_id': 'U26'},\n","  {'sentence_idx': '1',\n","   'sentence_text': \"The patient's symptoms were initially reported as fatigue and feeling tired.\",\n","   'utterance_id': 'U26'},\n","  {'sentence_idx': '2',\n","   'sentence_text': \"The prognosis is cautiously optimistic given the patient's current lifestyle and the presence of a history of diabetes.\",\n","   'utterance_id': 'U26'}],\n"," 'P': [{'sentence_idx': '0',\n","   'sentence_text': 'The management plan includes regular blood tests for the eyes and feet, monitoring for signs of diabetes and managing the disease with diet and exercise.',\n","   'utterance_id': 'U26'},\n","  {'sentence_idx': '1',\n","   'sentence_text': 'The patient will be advised to maintain a healthy lifestyle and follow-up appointments to monitor the disease and manage any changes.',\n","   'utterance_id': 'U26'},\n","  {'sentence_idx': '2',\n","   'sentence_text': 'The patient will be encouraged to maintain a healthy lifestyle and follow-up appointments to monitor the disease and manage any changes.',\n","   'utterance_id': 'U26'}]}"]},"metadata":{},"execution_count":76}]},{"cell_type":"markdown","source":["### Testing (step-by-step)"],"metadata":{"id":"hiTPgJ8U-p6Y"}},{"cell_type":"code","source":["# === Upload audio ===\n","name = 'fever_stomach'\n","audio_path = f\"/content/drive/MyDrive/ClinicalNotesGen/Data/audios/en/wav/{name}.wav\"\n","audio_id = upload_audio(fs, audio_path)\n","audio_id"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lk8Zo4Cn0u1w","executionInfo":{"status":"ok","timestamp":1750750977830,"user_tz":-420,"elapsed":2031,"user":{"displayName":"Unforgiven The","userId":"10817091228202119239"}},"outputId":"2579f116-0fe1-4d5d-fcab-055f2b5c1a56"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["ObjectId('685a57017772f10be9ac8ab8')"]},"metadata":{},"execution_count":29}]},{"cell_type":"code","source":["# Fetch audio as binary\n","audio_binary = get_audio(fs, audio_id)\n","\n","# Play it in Jupyter\n","Audio(data=audio_binary, autoplay=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":76,"output_embedded_package_id":"1Wy-BkMqoy1JOe0qBFhHw0I_rTBEgDHqZ"},"id":"SyLINDY1z5Wh","executionInfo":{"status":"ok","timestamp":1750750979165,"user_tz":-420,"elapsed":656,"user":{"displayName":"Unforgiven The","userId":"10817091228202119239"}},"outputId":"e729deac-b5fe-4e67-9673-244d7f159260"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"markdown","source":["- Dialogue2Text"],"metadata":{"id":"0ers9N78FL5C"}},{"cell_type":"code","source":["transcript_word, transcript = process_audio(audio_path, model_whisper, pipeline_diarization)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"0o2g9Zr3Ge3V","executionInfo":{"status":"ok","timestamp":1750752037636,"user_tz":-420,"elapsed":22059,"user":{"displayName":"Unforgiven The","userId":"10817091228202119239"}},"outputId":"6820035b-e9ee-45b6-9b50-588720e08534"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["INFO:speechbrain.utils.fetching:Fetch hyperparams.yaml: Using symlink found at '/root/.cache/torch/pyannote/speechbrain/hyperparams.yaml'\n","INFO:speechbrain.utils.fetching:Fetch custom.py: Fetching from HuggingFace Hub 'speechbrain/spkrec-ecapa-voxceleb' if not cached\n","DEBUG:speechbrain.utils.parameter_transfer:Collecting files (or symlinks) for pretraining in /root/.cache/torch/pyannote/speechbrain.\n","INFO:speechbrain.utils.fetching:Fetch embedding_model.ckpt: Using symlink found at '/root/.cache/torch/pyannote/speechbrain/embedding_model.ckpt'\n","DEBUG:speechbrain.utils.parameter_transfer:Set local path in self.paths[\"embedding_model\"] = /root/.cache/torch/pyannote/speechbrain/embedding_model.ckpt\n","INFO:speechbrain.utils.fetching:Fetch mean_var_norm_emb.ckpt: Using symlink found at '/root/.cache/torch/pyannote/speechbrain/mean_var_norm_emb.ckpt'\n","DEBUG:speechbrain.utils.parameter_transfer:Set local path in self.paths[\"mean_var_norm_emb\"] = /root/.cache/torch/pyannote/speechbrain/mean_var_norm_emb.ckpt\n","INFO:speechbrain.utils.fetching:Fetch classifier.ckpt: Using symlink found at '/root/.cache/torch/pyannote/speechbrain/classifier.ckpt'\n","DEBUG:speechbrain.utils.parameter_transfer:Set local path in self.paths[\"classifier\"] = /root/.cache/torch/pyannote/speechbrain/classifier.ckpt\n","INFO:speechbrain.utils.fetching:Fetch label_encoder.txt: Using symlink found at '/root/.cache/torch/pyannote/speechbrain/label_encoder.ckpt'\n","DEBUG:speechbrain.utils.parameter_transfer:Set local path in self.paths[\"label_encoder\"] = /root/.cache/torch/pyannote/speechbrain/label_encoder.ckpt\n","INFO:speechbrain.utils.parameter_transfer:Loading pretrained files for: embedding_model, mean_var_norm_emb, classifier, label_encoder\n","DEBUG:speechbrain.utils.parameter_transfer:Redirecting (loading from local path): embedding_model -> /root/.cache/torch/pyannote/speechbrain/embedding_model.ckpt\n","DEBUG:speechbrain.utils.parameter_transfer:Redirecting (loading from local path): mean_var_norm_emb -> /root/.cache/torch/pyannote/speechbrain/mean_var_norm_emb.ckpt\n","DEBUG:speechbrain.utils.parameter_transfer:Redirecting (loading from local path): classifier -> /root/.cache/torch/pyannote/speechbrain/classifier.ckpt\n","DEBUG:speechbrain.utils.parameter_transfer:Redirecting (loading from local path): label_encoder -> /root/.cache/torch/pyannote/speechbrain/label_encoder.ckpt\n","DEBUG:speechbrain.dataio.encoder:Loaded categorical encoding from /root/.cache/torch/pyannote/speechbrain/label_encoder.ckpt\n","/usr/local/lib/python3.11/dist-packages/pyannote/audio/utils/reproducibility.py:74: ReproducibilityWarning: TensorFloat-32 (TF32) has been disabled as it might lead to reproducibility issues and lower accuracy.\n","It can be re-enabled by calling\n","   >>> import torch\n","   >>> torch.backends.cuda.matmul.allow_tf32 = True\n","   >>> torch.backends.cudnn.allow_tf32 = True\n","See https://github.com/pyannote/pyannote-audio/issues/1370 for more details.\n","\n","  warnings.warn(\n"]}]},{"cell_type":"code","source":["transcript_word"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"D9KfvaRxwd94","executionInfo":{"status":"ok","timestamp":1750752058073,"user_tz":-420,"elapsed":15,"user":{"displayName":"Unforgiven The","userId":"10817091228202119239"}},"outputId":"6c74c809-e92e-40a5-bbdd-9ad27c8a0708"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[{'word': 'Hello,', 'start': np.float64(4.76), 'end': np.float64(5.44)},\n"," {'word': 'Mr.', 'start': np.float64(5.62), 'end': np.float64(5.86)},\n"," {'word': 'McKay.', 'start': np.float64(6.08), 'end': np.float64(6.42)},\n"," {'word': 'What', 'start': np.float64(7.28), 'end': np.float64(7.96)},\n"," {'word': 'brings', 'start': np.float64(7.96), 'end': np.float64(8.2)},\n"," {'word': 'you', 'start': np.float64(8.2), 'end': np.float64(8.48)},\n"," {'word': 'here', 'start': np.float64(8.48), 'end': np.float64(8.72)},\n"," {'word': 'today?', 'start': np.float64(8.72), 'end': np.float64(9.0)},\n"," {'word': 'I', 'start': np.float64(9.74), 'end': np.float64(10.42)},\n"," {'word': 'have', 'start': np.float64(10.42), 'end': np.float64(10.7)},\n"," {'word': 'a', 'start': np.float64(10.7), 'end': np.float64(10.84)},\n"," {'word': 'fever', 'start': np.float64(10.84), 'end': np.float64(11.3)},\n"," {'word': 'and', 'start': np.float64(11.3), 'end': np.float64(11.68)},\n"," {'word': 'a', 'start': np.float64(11.68), 'end': np.float64(11.9)},\n"," {'word': 'sore', 'start': np.float64(11.9), 'end': np.float64(12.26)},\n"," {'word': 'stomach.', 'start': np.float64(12.26), 'end': np.float64(12.76)},\n"," {'word': 'Okay,', 'start': np.float64(13.22), 'end': np.float64(13.76)},\n"," {'word': 'Tony.', 'start': np.float64(13.88), 'end': np.float64(14.16)},\n"," {'word': 'I', 'start': np.float64(15.28), 'end': np.float64(15.96)},\n"," {'word': 'see', 'start': np.float64(15.96), 'end': np.float64(16.28)},\n"," {'word': 'your', 'start': np.float64(16.28), 'end': np.float64(16.52)},\n"," {'word': 'temperature', 'start': np.float64(16.52), 'end': np.float64(17.0)},\n"," {'word': 'is', 'start': np.float64(17.0), 'end': np.float64(17.5)},\n"," {'word': '104', 'start': np.float64(17.5), 'end': np.float64(18.02)},\n"," {'word': 'degrees.', 'start': np.float64(18.02), 'end': np.float64(19.0)},\n"," {'word': \"That's\", 'start': np.float64(19.74), 'end': np.float64(20.42)},\n"," {'word': 'very', 'start': np.float64(20.42), 'end': np.float64(20.72)},\n"," {'word': 'high.', 'start': np.float64(20.72), 'end': np.float64(21.3)},\n"," {'word': 'Yes,', 'start': np.float64(22.24), 'end': np.float64(22.92)},\n"," {'word': 'I', 'start': np.float64(23.04), 'end': np.float64(23.36)},\n"," {'word': 'feel', 'start': np.float64(23.36), 'end': np.float64(23.62)},\n"," {'word': 'very', 'start': np.float64(23.62), 'end': np.float64(23.94)},\n"," {'word': 'dizzy', 'start': np.float64(23.94), 'end': np.float64(24.5)},\n"," {'word': 'and', 'start': np.float64(24.5), 'end': np.float64(24.78)},\n"," {'word': 'nauseous.', 'start': np.float64(24.78), 'end': np.float64(25.5)},\n"," {'word': 'Did', 'start': np.float64(25.8), 'end': np.float64(26.46)},\n"," {'word': 'you', 'start': np.float64(26.46), 'end': np.float64(26.6)},\n"," {'word': 'get', 'start': np.float64(26.6), 'end': np.float64(26.84)},\n"," {'word': 'sick?', 'start': np.float64(26.84), 'end': np.float64(27.2)},\n"," {'word': 'Yes,', 'start': np.float64(28.34), 'end': np.float64(29.12)},\n"," {'word': 'I', 'start': np.float64(29.38), 'end': np.float64(29.56)},\n"," {'word': 'vomited', 'start': np.float64(29.56), 'end': np.float64(30.22)},\n"," {'word': 'twice', 'start': np.float64(30.22), 'end': np.float64(30.58)},\n"," {'word': 'this', 'start': np.float64(30.58), 'end': np.float64(31.02)},\n"," {'word': 'morning.', 'start': np.float64(31.02), 'end': np.float64(31.38)},\n"," {'word': 'Did', 'start': np.float64(31.78), 'end': np.float64(32.18)},\n"," {'word': 'you', 'start': np.float64(32.18), 'end': np.float64(32.38)},\n"," {'word': 'have', 'start': np.float64(32.38), 'end': np.float64(32.64)},\n"," {'word': 'any', 'start': np.float64(32.64), 'end': np.float64(32.98)},\n"," {'word': 'diarrhea?', 'start': np.float64(32.98), 'end': np.float64(33.44)},\n"," {'word': 'Yes,', 'start': np.float64(34.3), 'end': np.float64(35.0)},\n"," {'word': 'a', 'start': np.float64(35.22), 'end': np.float64(35.58)},\n"," {'word': 'little', 'start': np.float64(35.58), 'end': np.float64(36.08)},\n"," {'word': 'bit.', 'start': np.float64(36.08), 'end': np.float64(36.36)},\n"," {'word': 'Did', 'start': np.float64(36.72), 'end': np.float64(37.14)},\n"," {'word': 'you', 'start': np.float64(37.14), 'end': np.float64(37.32)},\n"," {'word': 'take', 'start': np.float64(37.32), 'end': np.float64(37.56)},\n"," {'word': 'any', 'start': np.float64(37.56), 'end': np.float64(37.9)},\n"," {'word': 'medicine', 'start': np.float64(37.9), 'end': np.float64(38.3)},\n"," {'word': 'to', 'start': np.float64(38.3), 'end': np.float64(38.68)},\n"," {'word': 'treat', 'start': np.float64(38.68), 'end': np.float64(39.02)},\n"," {'word': 'your', 'start': np.float64(39.02), 'end': np.float64(39.26)},\n"," {'word': 'symptoms?', 'start': np.float64(39.26), 'end': np.float64(39.76)},\n"," {'word': 'No,', 'start': np.float64(40.42), 'end': np.float64(41.02)},\n"," {'word': 'doctor.', 'start': np.float64(41.02), 'end': np.float64(41.36)},\n"," {'word': 'I', 'start': np.float64(41.56), 'end': np.float64(42.02)},\n"," {'word': \"didn't\", 'start': np.float64(42.02), 'end': np.float64(42.3)},\n"," {'word': 'take', 'start': np.float64(42.3), 'end': np.float64(42.52)},\n"," {'word': 'anything.', 'start': np.float64(42.52), 'end': np.float64(42.86)},\n"," {'word': 'Okay,', 'start': np.float64(43.38), 'end': np.float64(44.02)},\n"," {'word': 'sounds', 'start': np.float64(44.22), 'end': np.float64(44.92)},\n"," {'word': 'like', 'start': np.float64(44.92), 'end': np.float64(45.24)},\n"," {'word': 'you', 'start': np.float64(45.24), 'end': np.float64(45.42)},\n"," {'word': 'may', 'start': np.float64(45.42), 'end': np.float64(45.64)},\n"," {'word': 'have', 'start': np.float64(45.64), 'end': np.float64(45.92)},\n"," {'word': 'some', 'start': np.float64(45.92), 'end': np.float64(46.24)},\n"," {'word': 'food', 'start': np.float64(46.24), 'end': np.float64(46.7)},\n"," {'word': 'poisoning.', 'start': np.float64(46.7), 'end': np.float64(47.22)},\n"," {'word': 'Oh,', 'start': np.float64(47.9), 'end': np.float64(48.36)},\n"," {'word': 'no.', 'start': np.float64(48.36), 'end': np.float64(48.9)},\n"," {'word': 'Take', 'start': np.float64(49.84), 'end': np.float64(50.62)},\n"," {'word': 'this', 'start': np.float64(50.62), 'end': np.float64(50.9)},\n"," {'word': 'medicine', 'start': np.float64(50.9), 'end': np.float64(51.36)},\n"," {'word': 'now', 'start': np.float64(51.36), 'end': np.float64(51.72)},\n"," {'word': 'and', 'start': np.float64(51.72), 'end': np.float64(52.22)},\n"," {'word': 'again', 'start': np.float64(52.22), 'end': np.float64(52.54)},\n"," {'word': 'every', 'start': np.float64(52.54), 'end': np.float64(53.04)},\n"," {'word': 'six', 'start': np.float64(53.04), 'end': np.float64(53.48)},\n"," {'word': 'hours', 'start': np.float64(53.48), 'end': np.float64(53.92)},\n"," {'word': 'until', 'start': np.float64(53.92), 'end': np.float64(54.38)},\n"," {'word': \"it's\", 'start': np.float64(54.38), 'end': np.float64(54.92)},\n"," {'word': 'finished.', 'start': np.float64(54.92), 'end': np.float64(55.24)},\n"," {'word': \"You'll\", 'start': np.float64(55.5), 'end': np.float64(56.04)},\n"," {'word': 'be', 'start': np.float64(56.04), 'end': np.float64(56.22)},\n"," {'word': 'okay.', 'start': np.float64(56.22), 'end': np.float64(56.66)},\n"," {'word': \"You'll\", 'start': np.float64(56.66), 'end': np.float64(56.9)},\n"," {'word': 'be', 'start': np.float64(56.9), 'end': np.float64(56.9)},\n"," {'word': 'okay', 'start': np.float64(56.9), 'end': np.float64(56.9)},\n"," {'word': 'in', 'start': np.float64(56.9), 'end': np.float64(57.06)},\n"," {'word': 'about', 'start': np.float64(57.06), 'end': np.float64(57.4)},\n"," {'word': '24', 'start': np.float64(57.4), 'end': np.float64(58.06)},\n"," {'word': 'hours.', 'start': np.float64(58.06), 'end': np.float64(58.6)},\n"," {'word': \"That's\", 'start': np.float64(59.2), 'end': np.float64(59.8)},\n"," {'word': 'a', 'start': np.float64(59.8), 'end': np.float64(59.8)},\n"," {'word': 'relief.', 'start': np.float64(59.8), 'end': np.float64(60.12)},\n"," {'word': 'Thank', 'start': np.float64(60.52), 'end': np.float64(61.12)},\n"," {'word': 'you', 'start': np.float64(61.12), 'end': np.float64(61.32)},\n"," {'word': 'very', 'start': np.float64(61.32), 'end': np.float64(61.5)},\n"," {'word': 'much,', 'start': np.float64(61.5), 'end': np.float64(61.86)},\n"," {'word': 'doctor.', 'start': np.float64(61.92), 'end': np.float64(62.16)},\n"," {'word': 'Thank', 'start': np.float64(62.16), 'end': np.float64(62.36)},\n"," {'word': 'you,', 'start': np.float64(62.36), 'end': np.float64(62.36)},\n"," {'word': 'doctor.', 'start': np.float64(62.36), 'end': np.float64(62.36)}]"]},"metadata":{},"execution_count":50}]},{"cell_type":"code","source":["transcript"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"vKhyU8XNwee2","executionInfo":{"status":"ok","timestamp":1750752062658,"user_tz":-420,"elapsed":4,"user":{"displayName":"Unforgiven The","userId":"10817091228202119239"}},"outputId":"f45fb535-5569-4587-f767-bb071d1d7476"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[{'speaker': 'SPEAKER_00',\n","  'start': np.float64(4.76),\n","  'end': np.float64(6.42),\n","  'text': 'Hello, Mr. McKay.',\n","  'utterance_id': 'U1'},\n"," {'speaker': 'SPEAKER_00',\n","  'start': np.float64(7.28),\n","  'end': np.float64(9.0),\n","  'text': 'What brings you here today?',\n","  'utterance_id': 'U2'},\n"," {'speaker': 'SPEAKER_01',\n","  'start': np.float64(9.74),\n","  'end': np.float64(14.16),\n","  'text': 'I have a fever and a sore stomach. Okay, Tony.',\n","  'utterance_id': 'U3'},\n"," {'speaker': 'SPEAKER_00',\n","  'start': np.float64(15.28),\n","  'end': np.float64(21.3),\n","  'text': \"I see your temperature is 104 degrees. That's very high.\",\n","  'utterance_id': 'U4'},\n"," {'speaker': 'SPEAKER_01',\n","  'start': np.float64(22.24),\n","  'end': np.float64(27.2),\n","  'text': 'Yes, I feel very dizzy and nauseous. Did you get sick?',\n","  'utterance_id': 'U5'},\n"," {'speaker': 'SPEAKER_01',\n","  'start': np.float64(28.34),\n","  'end': np.float64(35.0),\n","  'text': 'Yes, I vomited twice this morning. Did you have any diarrhea? Yes,',\n","  'utterance_id': 'U6'},\n"," {'speaker': 'SPEAKER_00',\n","  'start': np.float64(35.22),\n","  'end': np.float64(41.36),\n","  'text': 'a little bit. Did you take any medicine to treat your symptoms? No, doctor.',\n","  'utterance_id': 'U7'},\n"," {'speaker': 'SPEAKER_01',\n","  'start': np.float64(41.56),\n","  'end': np.float64(44.02),\n","  'text': \"I didn't take anything. Okay,\",\n","  'utterance_id': 'U8'},\n"," {'speaker': 'SPEAKER_00',\n","  'start': np.float64(44.22),\n","  'end': np.float64(48.9),\n","  'text': 'sounds like you may have some food poisoning. Oh, no.',\n","  'utterance_id': 'U9'},\n"," {'speaker': 'SPEAKER_00',\n","  'start': np.float64(49.84),\n","  'end': np.float64(59.8),\n","  'text': \"Take this medicine now and again every six hours until it's finished. You'll be okay. You'll be okay in about 24 hours. That's\",\n","  'utterance_id': 'U10'},\n"," {'speaker': 'SPEAKER_01',\n","  'start': np.float64(59.8),\n","  'end': np.float64(62.36),\n","  'text': 'a relief. Thank you very much, doctor. Thank you, doctor.',\n","  'utterance_id': 'U11'}]"]},"metadata":{},"execution_count":51}]},{"cell_type":"markdown","source":["- Role Classifier"],"metadata":{"id":"cl2PrQYeO9HI"}},{"cell_type":"code","source":["transcript_labelled = classify_speakers(transcript, doctor_keywords, patient_keywords)"],"metadata":{"id":"8olm8zCaPCE5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["transcript_labelled"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"JiBTM9__xW8Y","executionInfo":{"status":"ok","timestamp":1750752082671,"user_tz":-420,"elapsed":19,"user":{"displayName":"Unforgiven The","userId":"10817091228202119239"}},"outputId":"0bd1f32b-d2ba-49a1-f835-29e98c47a7fb"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[{'speaker': 'Doctor',\n","  'start': np.float64(4.76),\n","  'end': np.float64(6.42),\n","  'text': 'Hello, Mr. McKay.',\n","  'utterance_id': 'U1'},\n"," {'speaker': 'Doctor',\n","  'start': np.float64(7.28),\n","  'end': np.float64(9.0),\n","  'text': 'What brings you here today?',\n","  'utterance_id': 'U2'},\n"," {'speaker': 'Patient',\n","  'start': np.float64(9.74),\n","  'end': np.float64(14.16),\n","  'text': 'I have a fever and a sore stomach. Okay, Tony.',\n","  'utterance_id': 'U3'},\n"," {'speaker': 'Doctor',\n","  'start': np.float64(15.28),\n","  'end': np.float64(21.3),\n","  'text': \"I see your temperature is 104 degrees. That's very high.\",\n","  'utterance_id': 'U4'},\n"," {'speaker': 'Patient',\n","  'start': np.float64(22.24),\n","  'end': np.float64(27.2),\n","  'text': 'Yes, I feel very dizzy and nauseous. Did you get sick?',\n","  'utterance_id': 'U5'},\n"," {'speaker': 'Patient',\n","  'start': np.float64(28.34),\n","  'end': np.float64(35.0),\n","  'text': 'Yes, I vomited twice this morning. Did you have any diarrhea? Yes,',\n","  'utterance_id': 'U6'},\n"," {'speaker': 'Doctor',\n","  'start': np.float64(35.22),\n","  'end': np.float64(41.36),\n","  'text': 'a little bit. Did you take any medicine to treat your symptoms? No, doctor.',\n","  'utterance_id': 'U7'},\n"," {'speaker': 'Patient',\n","  'start': np.float64(41.56),\n","  'end': np.float64(44.02),\n","  'text': \"I didn't take anything. Okay,\",\n","  'utterance_id': 'U8'},\n"," {'speaker': 'Doctor',\n","  'start': np.float64(44.22),\n","  'end': np.float64(48.9),\n","  'text': 'sounds like you may have some food poisoning. Oh, no.',\n","  'utterance_id': 'U9'},\n"," {'speaker': 'Doctor',\n","  'start': np.float64(49.84),\n","  'end': np.float64(59.8),\n","  'text': \"Take this medicine now and again every six hours until it's finished. You'll be okay. You'll be okay in about 24 hours. That's\",\n","  'utterance_id': 'U10'},\n"," {'speaker': 'Patient',\n","  'start': np.float64(59.8),\n","  'end': np.float64(62.36),\n","  'text': 'a relief. Thank you very much, doctor. Thank you, doctor.',\n","  'utterance_id': 'U11'}]"]},"metadata":{},"execution_count":54}]},{"cell_type":"markdown","source":["- SOAP Gen"],"metadata":{"id":"Z4RkJpF5O4Bs"}},{"cell_type":"code","source":["dialogue = transcript2string(transcript_labelled)\n","summary = process_soap_traceability(dialogue, tok, tok_fast, ft_model)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xEf5W7HfO5j7","executionInfo":{"status":"ok","timestamp":1750752098464,"user_tz":-420,"elapsed":5508,"user":{"displayName":"Unforgiven The","userId":"10817091228202119239"}},"outputId":"5a7ad2b2-dd62-46e3-abe5-05afd210dcd4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["The following generation flags are not valid and may be ignored: ['length_penalty']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n","Passing a tuple of `past_key_values` is deprecated and will be removed in Transformers v4.58.0. You should pass an instance of `EncoderDecoderCache` instead, e.g. `past_key_values=EncoderDecoderCache.from_legacy_cache(past_key_values)`.\n"]},{"output_type":"stream","name":"stdout","text":["[INFO] Generated summary length: 792 characters, 164 tokens\n"]}]},{"cell_type":"code","source":["summary"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"WLow1AVrxmRY","executionInfo":{"status":"ok","timestamp":1750752102263,"user_tz":-420,"elapsed":46,"user":{"displayName":"Unforgiven The","userId":"10817091228202119239"}},"outputId":"c12d1da8-50a1-4e27-d5b3-24be57286dc8"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'utterances': {'U1': 'Doctor: Hello, Mr. McKay.',\n","  'U2': 'Doctor: What brings you here today?',\n","  'U3': 'Patient: I have a fever and a sore stomach. Okay, Tony.',\n","  'U4': \"Doctor: I see your temperature is 104 degrees. That's very high.\",\n","  'U5': 'Patient: Yes, I feel very dizzy and nauseous. Did you get sick?',\n","  'U6': 'Patient: Yes, I vomited twice this morning. Did you have any diarrhea? Yes,',\n","  'U7': 'Doctor: a little bit. Did you take any medicine to treat your symptoms? No, doctor.',\n","  'U8': \"Patient: I didn't take anything. Okay,\",\n","  'U9': 'Doctor: sounds like you may have some food poisoning. Oh, no.',\n","  'U10': \"Doctor: Take this medicine now and again every six hours until it's finished. You'll be okay. You'll be okay in about 24 hours. That's\",\n","  'U11': 'Patient: a relief. Thank you very much, doctor. Thank you, doctor.'},\n"," 'S': [{'sentence_idx': '0',\n","   'sentence_text': 'Patient, Tony McKay, presents with a fever and sore stomach.',\n","   'utterance_id': 'U3'},\n","  {'sentence_idx': '1',\n","   'sentence_text': 'He reports feeling dizzy and nauseous.',\n","   'utterance_id': 'U5'},\n","  {'sentence_idx': '2',\n","   'sentence_text': 'He has vomited twice this morning.',\n","   'utterance_id': 'U6'},\n","  {'sentence_idx': '3',\n","   'sentence_text': 'He denies taking any medicine to treat symptoms.',\n","   'utterance_id': 'U8'}],\n"," 'O': [{'sentence_idx': '0',\n","   'sentence_text': 'Physical examination reveals a temperature of 104 degrees.',\n","   'utterance_id': 'U4'},\n","  {'sentence_idx': '1',\n","   'sentence_text': 'He has a history of vomiting and diarrhea.',\n","   'utterance_id': 'U6'},\n","  {'sentence_idx': '2',\n","   'sentence_text': 'He denies any food poisoning.',\n","   'utterance_id': 'U9'},\n","  {'sentence_idx': '3',\n","   'sentence_text': 'No medication was taken.',\n","   'utterance_id': 'U8'}],\n"," 'A': [{'sentence_idx': '0',\n","   'sentence_text': 'Primary diagnosis is a high temperature and fever, secondary to food poisoning.',\n","   'utterance_id': 'U4'},\n","  {'sentence_idx': '1',\n","   'sentence_text': 'Differential diagnoses could include other causes of symptoms, but these are not considered at this time.',\n","   'utterance_id': 'U9'}],\n"," 'P': [{'sentence_idx': '0',\n","   'sentence_text': 'The patient is advised to take a six-hour course of anti-diarrheal medication every six hours until it is finished.',\n","   'utterance_id': 'U10'},\n","  {'sentence_idx': '1',\n","   'sentence_text': 'He will be treated with a 24-hour course of anti-diarrheal medication.',\n","   'utterance_id': 'U10'},\n","  {'sentence_idx': '2',\n","   'sentence_text': 'The patient is advised to report any new symptoms within 24 hours.',\n","   'utterance_id': 'U10'}]}"]},"metadata":{},"execution_count":56}]},{"cell_type":"code","source":["conversation_id = insert_conversation(db, audio_id, transcript, transcript_word, summary)\n","print(\"Inserted conversation ID:\", conversation_id)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"y26we7-09XZs","executionInfo":{"status":"ok","timestamp":1750752177629,"user_tz":-420,"elapsed":23,"user":{"displayName":"Unforgiven The","userId":"10817091228202119239"}},"outputId":"25c5eb6d-e370-40f7-a2fb-afb7c0ff0866"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Inserted conversation ID: 685a5bb17772f10be9ac8ac2\n"]}]}]}